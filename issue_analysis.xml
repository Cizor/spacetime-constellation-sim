<Objs Version="1.1.0.1" xmlns="http://schemas.microsoft.com/powershell/2004/04">
  <Obj RefId="0">
    <TN RefId="0">
      <T>System.Management.Automation.PSCustomObject</T>
      <T>System.Object</T>
    </TN>
    <MS>
      <S N="Topic">Logging</S>
      <I32 N="Issue1">179</I32>
      <S N="Title1">[Scope 4][Chunk 12] Add structured logging for CDPI, agents, scheduler &amp; telemetry</S>
      <S N="Body1">## Background_x000A__x000A_Scope 4 introduces a non-trivial SBI stack:_x000A__x000A_- CDPI server on the controller:_x000A_  - Handles `ReceiveRequests` streams from multiple agents._x000A_  - Sends `CreateEntry`, `DeleteEntry`, `Finalize`, and (optionally) `SetSrPolicy` / `DeleteSrPolicy`._x000A_  - Receives `Hello`, `Reset`, and `Response` messages._x000A_- Per-node Agents:_x000A_  - Maintain a local schedule of `ScheduledAction`s via `EventScheduler`._x000A_  - Execute beam/route actions against `ScenarioState`._x000A_  - Emit telemetry via `TelemetryService.ExportMetrics`._x000A_- Controller-side TelemetryService:_x000A_  - Receives `ExportMetricsRequest`._x000A_  - Updates `TelemetryState` with per-interface metrics._x000A__x000A_Right now, most of this code is either lightly logged or only uses ad-hoc `fmt.Printf`-style debugging. For Scope 4 to be debuggable in real scenarios, we need consistent **structured logging** across:_x000A__x000A_- CDPI server (controller-side SBI scheduling stream)._x000A_- Agents (per-node schedule execution)._x000A_- Telemetry (agent emission + controller ingestion)._x000A_- Scheduler (Chunk 8) where it exists._x000A__x000A_The design goal is:_x000A__x000A_- Make it easy to trace:_x000A_  - “What did the scheduler tell agent X to do?”_x000A_  - “Did agent X schedule &amp; execute the action at the right time?”_x000A_  - “Did we get telemetry for the links/routes that should be active?”_x000A_- Without:_x000A_  - Dumping huge volumes of unstructured logs._x000A_  - Tight-coupling to a specific logging backend._x000A__x000A_This issue focuses on **adding structured logging hooks and a minimal logging interface**, not wiring to external logging systems._x000A__x000A_## Goal_x000A__x000A_Introduce a small, consistent logging abstraction and use it to emit structured logs for:_x000A__x000A_- CDPI server major events._x000A_- Agent lifecycle &amp; schedule execution._x000A_- Telemetry server ingest._x000A_- (Optionally) Scheduler decisions where it is already implemented._x000A__x000A_The logging should:_x000A__x000A_- Be safe to call from hot paths._x000A_- Use a simple key–value style, so it can be consumed by text logs now and structured systems later._x000A_- Be configurable at least by log level (e.g. INFO vs DEBUG)._x000A__x000A_## Where to look_x000A__x000A_- CDPI server (controller):_x000A__x000A_  - `internal/sbi/controller/cdpi_server.go` (or equivalent)._x000A_  - Types like:_x000A__x000A_        type CDPIServer struct {_x000A_            scheduling.UnimplementedControlDataPlaneInterfaceServer_x000A__x000A_            State    *simstate.ScenarioState_x000A_            Clock    sbi.EventScheduler_x000A_            agentsMu sync.RWMutex_x000A_            agents   map[string]*AgentHandle_x000A_            Logger   Logger // to be added_x000A_        }_x000A__x000A_        type AgentHandle struct {_x000A_            AgentID  string_x000A_            NodeID   string_x000A_            Stream   scheduling.ControlDataPlaneInterface_ReceiveRequestsServer_x000A_            outgoing chan *scheduling.ReceiveRequestsMessageFromController_x000A_            token    string_x000A_        }_x000A__x000A_- Agent implementation:_x000A__x000A_  - `internal/sbi/agent/agent.go` (or similar)._x000A_  - `Agent` struct where we already have:_x000A_    - `AgentID`, `NodeID`._x000A_    - `State`, `Scheduler`, CDPI stream, telemetry client._x000A_    - Telemetry loop fields from Chunk 6._x000A__x000A_- Telemetry server:_x000A__x000A_  - `internal/sbi/controller/telemetry_server.go` (or similar)._x000A_  - `TelemetryServer` type that implements `TelemetryServiceServer`._x000A__x000A_- Scheduler (Chunk 8):_x000A__x000A_  - `internal/sbi/controller/scheduler.go`._x000A_  - Where scheduled actions are created and `SendCreateEntry` / `SendDeleteEntry` / `SendFinalize` are called._x000A__x000A_Search terms:_x000A__x000A_- `CDPIServer`_x000A_- `Agent struct`_x000A_- `TelemetryServer`_x000A_- `Scheduler struct`_x000A_- `Logger` (if any existing minimal logging helpers)_x000A__x000A_## Tasks_x000A__x000A_### 1. Define a minimal Logger interface_x000A__x000A_Introduce a small logging abstraction in a shared SBI package, for example `internal/sbi/logging` or directly in `internal/sbi`:_x000A__x000A_- Define an interface:_x000A__x000A_      type Logger interface {_x000A_          Debug(msg string, kv ...any)_x000A_          Info(msg string, kv ...any)_x000A_          Warn(msg string, kv ...any)_x000A_          Error(msg string, kv ...any)_x000A_      }_x000A__x000A_- Provide a simple default implementation, e.g. `StdLogger`:_x000A__x000A_      type StdLogger struct {_x000A_          Level LogLevel_x000A_      }_x000A__x000A_      type LogLevel int_x000A__x000A_      const (_x000A_          LevelDebug LogLevel = iota_x000A_          LevelInfo_x000A_          LevelWarn_x000A_          LevelError_x000A_      )_x000A__x000A_      func (l *StdLogger) Debug(msg string, kv ...any) { /* no-op if Level &gt; Debug */ }_x000A_      func (l *StdLogger) Info(msg string, kv ...any)  { /* print line with key=val pairs */ }_x000A_      func (l *StdLogger) Warn(msg string, kv ...any)  { /* ... */ }_x000A_      func (l *StdLogger) Error(msg string, kv ...any) { /* ... */ }_x000A__x000A_Notes:_x000A__x000A_- For now, it’s fine to have a naive implementation using `log.Printf` with a simple `msg key=value key2=value2` format._x000A_- Keep the interface small so it can later be wired to `zap`, `slog`, or any other backend._x000A_- Provide a helper constructor, e.g. `NewStdLogger(level LogLevel) *StdLogger`._x000A__x000A_### 2. Thread Logger through CDPIServer_x000A__x000A_Extend `CDPIServer`:_x000A__x000A_- Add a `Logger` field:_x000A__x000A_      type CDPIServer struct {_x000A_          scheduling.UnimplementedControlDataPlaneInterfaceServer_x000A__x000A_          State    *simstate.ScenarioState_x000A_          Clock    sbi.EventScheduler_x000A_          agentsMu sync.RWMutex_x000A_          agents   map[string]*AgentHandle_x000A__x000A_          Logger sbi.Logger_x000A_      }_x000A__x000A_- Ensure construction helpers (e.g. `NewCDPIServer`) accept a `Logger`, defaulting to `NewStdLogger(LevelInfo)` if nil._x000A__x000A_Add logs for key events:_x000A__x000A_- Agent connection:_x000A__x000A_  - When `ReceiveRequests` sees the initial `Hello`:_x000A__x000A_        s.Logger.Info("cdpi: agent connected",_x000A_            "agent_id", agentID,_x000A_            "node_id", nodeID,_x000A_        )_x000A__x000A_- Agent reset:_x000A__x000A_        s.Logger.Info("cdpi: agent reset",_x000A_            "agent_id", agentID,_x000A_            "token", newToken,_x000A_        )_x000A__x000A_- CreateEntry / DeleteEntry / Finalize send:_x000A__x000A_  - Inside `SendCreateEntry` / `SendDeleteEntry` / `SendFinalize`:_x000A__x000A_        s.Logger.Debug("cdpi: send create entry",_x000A_            "agent_id", agentID,_x000A_            "entry_id", action.EntryID,_x000A_            "when", action.When,_x000A_            "type", action.Type,_x000A_        )_x000A__x000A_        s.Logger.Debug("cdpi: send delete entry",_x000A_            "agent_id", agentID,_x000A_            "entry_id", entryID,_x000A_        )_x000A__x000A_        s.Logger.Debug("cdpi: send finalize",_x000A_            "agent_id", agentID,_x000A_            "cutoff", cutoff,_x000A_        )_x000A__x000A_- Responses from agents:_x000A__x000A_  - In stream read loop when agent sends a `Response`:_x000A__x000A_        s.Logger.Debug("cdpi: response from agent",_x000A_            "agent_id", agentID,_x000A_            "request_id", resp.RequestId,_x000A_            "status", resp.Status,_x000A_        )_x000A__x000A_- Errors:_x000A__x000A_  - Stream errors, missing agent entries, etc., should log via `Warn` or `Error`._x000A__x000A_### 3. Add Logger to Agent and log lifecycle &amp; execution_x000A__x000A_Extend `Agent` struct to include a logger:_x000A__x000A_- Add field:_x000A__x000A_      type Agent struct {_x000A_          AgentID   string_x000A_          NodeID    string_x000A_          State     *simstate.ScenarioState_x000A_          Scheduler sbi.EventScheduler_x000A__x000A_          TelemetryClient telemetry.TelemetryServiceClient_x000A_          TelemetryInterval time.Duration_x000A__x000A_          Stream scheduling.ControlDataPlaneInterface_ReceiveRequestsClient_x000A__x000A_          // scheduling, telemetry, etc..._x000A_          Logger sbi.Logger_x000A_      }_x000A__x000A_- Ensure Agent constructors (or wiring in Chunk 9) pass a logger (or default)._x000A__x000A_Add logs:_x000A__x000A_- Start/Stop:_x000A__x000A_      func (a *Agent) Start(ctx context.Context) error {_x000A_          if a.Logger != nil {_x000A_              a.Logger.Info("agent: start",_x000A_                  "agent_id", a.AgentID,_x000A_                  "node_id", a.NodeID,_x000A_              )_x000A_          }_x000A_          // existing startup logic..._x000A_      }_x000A__x000A_      func (a *Agent) Stop() {_x000A_          if a.Logger != nil {_x000A_              a.Logger.Info("agent: stop",_x000A_                  "agent_id", a.AgentID,_x000A_                  "node_id", a.NodeID,_x000A_              )_x000A_          }_x000A_          // cleanup..._x000A_      }_x000A__x000A_- Scheduling actions (when Agent receives `CreateEntry` / `DeleteEntry` / `Finalize`):_x000A__x000A_      a.Logger.Debug("agent: schedule action",_x000A_          "agent_id", a.AgentID,_x000A_          "entry_id", act.EntryID,_x000A_          "when", act.When,_x000A_          "type", act.Type,_x000A_      )_x000A__x000A_- Executing actions:_x000A__x000A_      a.Logger.Debug("agent: execute action",_x000A_          "agent_id", a.AgentID,_x000A_          "entry_id", act.EntryID,_x000A_          "type", act.Type,_x000A_      )_x000A__x000A_- Errors applying KB updates:_x000A__x000A_      a.Logger.Warn("agent: action failed",_x000A_          "agent_id", a.AgentID,_x000A_          "entry_id", act.EntryID,_x000A_          "err", err,_x000A_      )_x000A__x000A_- Telemetry ticks (DEBUG-level):_x000A__x000A_      a.Logger.Debug("agent: telemetry tick",_x000A_          "agent_id", a.AgentID,_x000A_          "node_id", a.NodeID,_x000A_          "num_if", len(metrics),_x000A_      )_x000A__x000A_- Telemetry export errors (already similar from Chunk 6, but convert to new `Logger`):_x000A__x000A_      a.Logger.Warn("agent: telemetry export failed",_x000A_          "agent_id", a.AgentID,_x000A_          "err", err,_x000A_      )_x000A__x000A_### 4. Add Logger to TelemetryServer_x000A__x000A_Extend `TelemetryServer`:_x000A__x000A_- Add field:_x000A__x000A_      type TelemetryServer struct {_x000A_          telemetry.UnimplementedTelemetryServiceServer_x000A__x000A_          Telemetry *TelemetryState_x000A_          Logger    sbi.Logger_x000A_      }_x000A__x000A_- In `ExportMetrics`:_x000A__x000A_      s.Logger.Debug("telemetry: export metrics",_x000A_          "num_if", len(req.InterfaceMetrics),_x000A_      )_x000A__x000A_      for _, im := range req.InterfaceMetrics {_x000A_          s.Logger.Debug("telemetry: interface metrics",_x000A_              "node_id", im.NodeId,_x000A_              "iface_id", im.InterfaceId,_x000A_              "up", im.Up,_x000A_              "bytes_tx", im.BytesTx,_x000A_          )_x000A_      }_x000A__x000A_- Log errors if any validation or update fails._x000A__x000A_### 5. Optional: Scheduler logging hooks_x000A__x000A_If the Scheduler (Chunk 8) is already in place, extend it with logger:_x000A__x000A_- Add `Logger sbi.Logger` to the `Scheduler` struct._x000A_- Log:_x000A__x000A_  - When computing schedules:_x000A__x000A_        s.Logger.Info("scheduler: run",_x000A_            "time", s.Clock.Now(),_x000A_        )_x000A__x000A_  - When emitting CreateEntry/Finalize:_x000A__x000A_        s.Logger.Debug("scheduler: schedule link interval",_x000A_            "link_id", linkID,_x000A_            "agent_id", agentID,_x000A_            "t_on", tOn,_x000A_            "t_off", tOff,_x000A_        )_x000A__x000A_### 6. Configuration &amp; wiring_x000A__x000A_- Decide a default logging level (e.g. INFO)._x000A_- In the main wiring (Chunk 9):_x000A__x000A_  - Create one or more `Logger` instances (e.g. shared `StdLogger`)._x000A_  - Pass them into:_x000A_    - `CDPIServer`._x000A_    - `TelemetryServer`._x000A_    - `Scheduler`._x000A_    - Each `Agent`._x000A__x000A_- Optionally add config hooks (not mandatory in this issue):_x000A__x000A_  - Command-line flag or config file setting for log level._x000A__x000A_### 7. Tests &amp; sanity checks_x000A__x000A_- Add simple tests for `StdLogger`:_x000A__x000A_  - At least verify that:_x000A_    - Calling `Debug` doesn’t panic when `Level` is INFO._x000A_    - Methods accept odd numbers of `kv` args gracefully (either ignore last or log anyway)._x000A_  - You don’t need heavy assertions on output, but you can test formatting helpers if extracted._x000A__x000A_- For CDPI / Agent / Telemetry tests:_x000A__x000A_  - It’s enough to:_x000A_    - Inject a no-op logger (`NilLogger`) in existing unit tests to avoid noisy output._x000A_    - Optionally add a small test with a fake logger that records calls to ensure no nil dereferences and some key events are logged._x000A__x000A_## Acceptance criteria_x000A__x000A_- Logging abstraction:_x000A__x000A_  - `Logger` interface exists with `Debug`, `Info`, `Warn`, `Error`._x000A_  - `StdLogger` (or similar) default implementation provided._x000A_  - It is safe to use from multiple goroutines._x000A__x000A_- CDPI server logging:_x000A__x000A_  - Logs agent connections (`Hello`), resets, and stream closures._x000A_  - Logs all outgoing Create/Delete/Finalize actions with `agent_id`, `entry_id`, `when`, `type`._x000A_  - Logs responses from agents with `agent_id`, `request_id`, and `status`._x000A__x000A_- Agent logging:_x000A__x000A_  - Logs startup and shutdown with `agent_id` and `node_id`._x000A_  - Logs schedule operations:_x000A_    - When actions are scheduled (CreateEntry)._x000A_    - When actions are cancelled (DeleteEntry / Finalize)._x000A_    - When actions execute and when they fail KB updates._x000A_  - Logs telemetry ticks (at DEBUG level) and ExportMetrics failures (at WARN/ERROR)._x000A__x000A_- Telemetry logging:_x000A__x000A_  - `TelemetryServer` logs in-bound `ExportMetricsRequest` summaries._x000A_  - Optionally logs per-interface metrics at DEBUG level._x000A_  - Logs any update/validation errors when updating `TelemetryState`._x000A__x000A_- Wiring:_x000A__x000A_  - CDPIServer, Scheduler (if present), Agents, and TelemetryServer all accept a `Logger` and use it, defaulting to a sane `StdLogger` if none is provided._x000A_  - Existing unit tests pass using a no-op logger where necessary._x000A__x000A_- Repository health:_x000A__x000A_  - `go build ./...` passes with the new logging abstractions._x000A_  - `go test ./...` passes, including any updated tests._x000A_</S>
      <S N="State1">open</S>
      <I32 N="Issue2">180</I32>
      <S N="Title2">[Scope 4][Chunk 12] Add structured logging for CDPI server and agents</S>
      <S N="Body2">## Background_x000A__x000A_By this point in **Scope 4** you have:_x000A__x000A_- A working **CDPI server**:_x000A_  - Handles `ReceiveRequests` streams from agents._x000A_  - Sends `CreateEntry`, `DeleteEntry`, `Finalize`, and (optionally) `SetSrPolicy` / `DeleteSrPolicy`._x000A_  - Tracks per-agent handles (`AgentHandle` with `AgentID`, `NodeID`, token, etc.)._x000A_- A functional **Agent** implementation:_x000A_  - Maintains a local schedule (`pending` map of `ScheduledAction`)._x000A_  - Uses `EventScheduler` to execute actions at the correct sim time._x000A_  - Sends `Response` and `Reset` messages back to the controller._x000A_- A **TelemetryService** and agent-side telemetry loop:_x000A_  - Periodic `ExportMetrics` calls with `InterfaceMetrics`._x000A__x000A_Mechanically, SBI is in decent shape, but **observability is still weak**:_x000A__x000A_- Debugging requires stepping through code or sprinkling ad-hoc `fmt.Printf`._x000A_- It’s hard to answer basic questions from logs alone:_x000A_  - “What did this agent schedule for the next 30 seconds?”_x000A_  - “Which actions were sent to this agent, with which token and seqno?”_x000A_  - “Did the agent execute `UpdateBeam` at the right sim time?”_x000A_  - “Are telemetry reports actually flowing, and how many per node?”_x000A__x000A_Chunk 12 focuses on **structured logging and basic developer observability**.  _x000A_This issue covers the **core structured logging for CDPI server and agents**; later issues will add counters, debug dumps, and helper tools._x000A__x000A_## Goal_x000A__x000A_Introduce **consistent, structured logging** across CDPI and Agent code paths so that:_x000A__x000A_- Each major SBI event produces a concise, structured log line:_x000A_  - CDPI:_x000A_    - Agent connect / Hello._x000A_    - Reset handling (new token)._x000A_    - Create/Delete/Finalize messages sent to agents._x000A_    - Responses received from agents._x000A_  - Agent:_x000A_    - Telemetry loop start/stop._x000A_    - Scheduled actions created/cancelled._x000A_    - Scheduled actions executed (including failures)._x000A_    - Reset and Finalize handling._x000A_- Logs include **key identifiers**:_x000A_  - `agent_id`, `node_id`, `entry_id`, `request_id`, `seqno`, `token`, `when` (sim-time), `action_type`, status, error._x000A_- Logging is **centralised** via a simple `Logger` interface:_x000A_  - So tests can plug in a no-op or buffer logger._x000A_  - Production code can plug in a real logger (zap, logrus, stdlib wrapper, etc.)._x000A_- Existing code is refactored to use the logger instead of random `fmt.Println` / ad-hoc prints (if any)._x000A__x000A_## Where to look_x000A__x000A_CDPI server (controller side):_x000A__x000A_- Likely under `internal/sbi/controller`, for example:_x000A__x000A_      internal/sbi/controller/cdpi_server.go_x000A__x000A_- Types:_x000A__x000A_      type CDPIServer struct {_x000A_          scheduling.UnimplementedControlDataPlaneInterfaceServer_x000A__x000A_          State    *simstate.ScenarioState_x000A_          Clock    EventScheduler_x000A_          agentsMu sync.RWMutex_x000A_          agents   map[string]*AgentHandle_x000A__x000A_          Logger   Logger // to be added_x000A_      }_x000A__x000A_      type AgentHandle struct {_x000A_          AgentID  string_x000A_          NodeID   string_x000A_          Stream   scheduling.ControlDataPlaneInterface_ReceiveRequestsServer_x000A_          outgoing chan *scheduling.ReceiveRequestsMessageFromController_x000A_          token    string_x000A_      }_x000A__x000A_Agent implementation:_x000A__x000A_- Under `internal/sbi/agent`, for example:_x000A__x000A_      internal/sbi/agent/agent.go_x000A__x000A_- Core fields:_x000A__x000A_      type Agent struct {_x000A_          AgentID   string_x000A_          NodeID    string_x000A_          State     *simstate.ScenarioState_x000A_          Scheduler EventScheduler_x000A__x000A_          Stream scheduling.ControlDataPlaneInterface_ReceiveRequestsClient_x000A__x000A_          // Telemetry fields, pending schedule, token, etc._x000A_          Logger Logger // to be added_x000A_      }_x000A__x000A_Existing logging (if any):_x000A__x000A_- Search for `fmt.Printf`, `log.Printf`, or `TODO: logging`._x000A_- Also search for comments in Scope 4 docs suggesting “log this” behaviour:_x000A_  - `CreateEntryRequest`, `DeleteEntryRequest`, `FinalizeRequest`, `Reset`, `Response`._x000A__x000A_Search terms:_x000A__x000A_- `CDPIServer`_x000A_- `AgentHandle`_x000A_- `Agent struct`_x000A_- `ResetRequest`_x000A_- `CreateEntryRequest`_x000A_- `FinalizeRequest`_x000A_- `ScheduledAction`_x000A__x000A_## Tasks_x000A__x000A_### 1. Define a small Logger interface and helpers_x000A__x000A_Add a **minimal logger abstraction** in a shared SBI package, e.g. `internal/sbi/logging.go`:_x000A__x000A_- Interface:_x000A__x000A_      type Logger interface {_x000A_          Debug(msg string, kv ...interface{})_x000A_          Info(msg string, kv ...interface{})_x000A_          Warn(msg string, kv ...interface{})_x000A_          Error(msg string, kv ...interface{})_x000A_      }_x000A__x000A_- Provide a simple default implementation using `log.Printf` or the stdlib, e.g.:_x000A__x000A_      type StdLogger struct{}_x000A__x000A_      func (l *StdLogger) logf(level string, msg string, kv ...interface{}) {_x000A_          // Flatten kv into key=value pairs; keep it simple._x000A_          // Example format: "level=INFO msg='...' agent_id=... entry_id=..."_x000A_      }_x000A__x000A_      func (l *StdLogger) Debug(msg string, kv ...interface{}) { /* ... */ }_x000A_      func (l *StdLogger) Info(msg string, kv ...interface{})  { /* ... */ }_x000A_      func (l *StdLogger) Warn(msg string, kv ...interface{})  { /* ... */ }_x000A_      func (l *StdLogger) Error(msg string, kv ...interface{}) { /* ... */ }_x000A__x000A_- Optionally define a **NoopLogger** for tests:_x000A__x000A_      type NoopLogger struct{}_x000A__x000A_      func (NoopLogger) Debug(string, ...interface{}) {}_x000A_      func (NoopLogger) Info(string, ...interface{})  {}_x000A_      func (NoopLogger) Warn(string, ...interface{})  {}_x000A_      func (NoopLogger) Error(string, ...interface{}) {}_x000A__x000A_- Provide a helper:_x000A__x000A_      func DefaultLogger() Logger { return &amp;StdLogger{} }_x000A__x000A_Design note:_x000A__x000A_- Keep this simple and dependency-free; this issue is about wiring in **structured log points**, not choosing a production-grade logging stack._x000A__x000A_### 2. Add Logger field to CDPIServer and Agent_x000A__x000A_Update CDPI server:_x000A__x000A_- Extend `CDPIServer`:_x000A__x000A_      type CDPIServer struct {_x000A_          scheduling.UnimplementedControlDataPlaneInterfaceServer_x000A__x000A_          State    *simstate.ScenarioState_x000A_          Clock    EventScheduler_x000A_          agentsMu sync.RWMutex_x000A_          agents   map[string]*AgentHandle_x000A__x000A_          Logger   Logger_x000A_      }_x000A__x000A_- In the constructor (or wherever `CDPIServer` is created):_x000A__x000A_      func NewCDPIServer(state *simstate.ScenarioState, clock EventScheduler, logger Logger) *CDPIServer {_x000A_          if logger == nil {_x000A_              logger = DefaultLogger()_x000A_          }_x000A_          return &amp;CDPIServer{_x000A_              State:  state,_x000A_              Clock:  clock,_x000A_              agents: make(map[string]*AgentHandle),_x000A_              Logger: logger,_x000A_          }_x000A_      }_x000A__x000A_Update Agent:_x000A__x000A_- Extend `Agent`:_x000A__x000A_      type Agent struct {_x000A_          AgentID   string_x000A_          NodeID    string_x000A_          State     *simstate.ScenarioState_x000A_          Scheduler EventScheduler_x000A__x000A_          Stream scheduling.ControlDataPlaneInterface_ReceiveRequestsClient_x000A__x000A_          // telemetry and scheduling fields..._x000A__x000A_          Logger Logger_x000A_      }_x000A__x000A_- Provide a constructor:_x000A__x000A_      func NewAgent(id, nodeID string, state *simstate.ScenarioState, sched EventScheduler, logger Logger) *Agent {_x000A_          if logger == nil {_x000A_              logger = DefaultLogger()_x000A_          }_x000A_          return &amp;Agent{_x000A_              AgentID:   id,_x000A_              NodeID:    nodeID,_x000A_              State:     state,_x000A_              Scheduler: sched,_x000A_              Logger:    logger,_x000A_              // initialise maps, etc._x000A_          }_x000A_      }_x000A__x000A_Design notes:_x000A__x000A_- Existing code that manually constructs these structs should migrate to `NewCDPIServer` / `NewAgent` (or an equivalent pattern)._x000A_- Tests can pass a `NoopLogger` or a small `TestLogger` that buffers entries._x000A__x000A_### 3. Instrument CDPIServer with structured logs_x000A__x000A_In `CDPIServer.ReceiveRequests`:_x000A__x000A_- On **agent Hello** (first message):_x000A__x000A_      s.Logger.Info("cdpi: agent hello",_x000A_          "agent_id", agentID,_x000A_          "node_id", nodeID,_x000A_      )_x000A__x000A_- On **ResetRequest** handling:_x000A__x000A_      s.Logger.Info("cdpi: reset received",_x000A_          "agent_id", agentID,_x000A_          "old_token", oldToken,_x000A_          "new_token", newToken,_x000A_      )_x000A__x000A_- On **CreateEntryRequest** being sent (from `SendCreateEntry`):_x000A__x000A_      s.Logger.Debug("cdpi: send create entry",_x000A_          "agent_id", agentID,_x000A_          "entry_id", action.EntryID,_x000A_          "when", action.When,_x000A_          "type", action.Type,_x000A_          "request_id", reqID,_x000A_          "seqno", seqNo,_x000A_          "token", token,_x000A_      )_x000A__x000A_- On **DeleteEntryRequest** being sent:_x000A__x000A_      s.Logger.Debug("cdpi: send delete entry",_x000A_          "agent_id", agentID,_x000A_          "entry_id", entryID,_x000A_          "request_id", reqID,_x000A_          "seqno", seqNo,_x000A_          "token", token,_x000A_      )_x000A__x000A_- On **FinalizeRequest**:_x000A__x000A_      s.Logger.Info("cdpi: send finalize",_x000A_          "agent_id", agentID,_x000A_          "cutoff_time", cutoffTime,_x000A_          "request_id", reqID,_x000A_          "seqno", seqNo,_x000A_      )_x000A__x000A_- On **Response** received from agent:_x000A__x000A_      s.Logger.Info("cdpi: response received",_x000A_          "agent_id", agentID,_x000A_          "request_id", resp.RequestId,_x000A_          "status", resp.Status,_x000A_      )_x000A__x000A_- On **stream close or error**:_x000A__x000A_      s.Logger.Warn("cdpi: agent stream closed",_x000A_          "agent_id", agentID,_x000A_          "err", err,_x000A_      )_x000A__x000A_Make sure:_x000A__x000A_- Logs are **non-spammy** (DEBUG vs INFO levels used sensibly)._x000A_- All logs include at least `agent_id`, plus `entry_id` or `request_id` where applicable._x000A__x000A_### 4. Instrument Agent with structured logs_x000A__x000A_In `Agent.Start`:_x000A__x000A_- On startup:_x000A__x000A_      a.Logger.Info("agent: start",_x000A_          "agent_id", a.AgentID,_x000A_          "node_id", a.NodeID,_x000A_      )_x000A__x000A_- On stream connect / Hello send:_x000A__x000A_      a.Logger.Debug("agent: sending hello",_x000A_          "agent_id", a.AgentID,_x000A_          "node_id", a.NodeID,_x000A_      )_x000A__x000A_- On **Reset** RPC call to controller (if implemented):_x000A__x000A_      a.Logger.Info("agent: sending reset",_x000A_          "agent_id", a.AgentID,_x000A_      )_x000A__x000A_In the **agent receive loop** for CDPI messages:_x000A__x000A_- On **CreateEntryRequest**:_x000A__x000A_      a.Logger.Debug("agent: received create entry",_x000A_          "agent_id", a.AgentID,_x000A_          "entry_id", entryID,_x000A_          "when", when,_x000A_          "type", actionType,_x000A_          "seqno", seqNo,_x000A_          "token", token,_x000A_      )_x000A__x000A_- On **DeleteEntryRequest**:_x000A__x000A_      a.Logger.Debug("agent: received delete entry",_x000A_          "agent_id", a.AgentID,_x000A_          "entry_id", entryID,_x000A_          "seqno", seqNo,_x000A_          "token", token,_x000A_      )_x000A__x000A_- On **FinalizeRequest**:_x000A__x000A_      a.Logger.Info("agent: received finalize",_x000A_          "agent_id", a.AgentID,_x000A_          "cutoff_time", cutoffTime,_x000A_      )_x000A__x000A_- On **token mismatch**:_x000A__x000A_      a.Logger.Warn("agent: token mismatch, ignoring message",_x000A_          "agent_id", a.AgentID,_x000A_          "expected_token", a.token,_x000A_          "received_token", token,_x000A_      )_x000A__x000A_In the **scheduler execution path**:_x000A__x000A_- When scheduling an action:_x000A__x000A_      a.Logger.Debug("agent: schedule action",_x000A_          "agent_id", a.AgentID,_x000A_          "entry_id", action.EntryID,_x000A_          "when", action.When,_x000A_          "type", action.Type,_x000A_      )_x000A__x000A_- In `execute(action *ScheduledAction)`:_x000A__x000A_      a.Logger.Info("agent: execute action",_x000A_          "agent_id", a.AgentID,_x000A_          "entry_id", action.EntryID,_x000A_          "type", action.Type,_x000A_          "when", a.Scheduler.Now(),_x000A_      )_x000A__x000A_      // On error:_x000A_      a.Logger.Error("agent: execute action failed",_x000A_          "agent_id", a.AgentID,_x000A_          "entry_id", action.EntryID,_x000A_          "type", action.Type,_x000A_          "err", err,_x000A_      )_x000A__x000A_In the **telemetry loop**:_x000A__x000A_- On telemetry tick (optional but useful):_x000A__x000A_      a.Logger.Debug("agent: telemetry tick",_x000A_          "agent_id", a.AgentID,_x000A_          "node_id", a.NodeID,_x000A_          "interval_sec", deltaSec,_x000A_          "num_interfaces", len(metrics),_x000A_      )_x000A__x000A_- On `ExportMetrics` failure (you likely already have this):_x000A__x000A_      a.Logger.Warn("agent: ExportMetrics failed",_x000A_          "agent_id", a.AgentID,_x000A_          "err", err,_x000A_      )_x000A__x000A_### 5. Clean up ad-hoc logging and wire logger in tests_x000A__x000A_- Search the SBI code for `fmt.Printf`, `log.Printf`, or similar, and:_x000A_  - Replace them with calls to `Logger` at appropriate severity._x000A_  - Remove noisy or redundant logging calls if they don’t add value._x000A__x000A_- Update tests:_x000A__x000A_  - Where CDPIServer / Agent are created:_x000A_    - Pass a `NoopLogger` or a small `TestLogger`:_x000A__x000A_          logger := &amp;NoopLogger{}_x000A_          server := NewCDPIServer(state, clock, logger)_x000A_          agent := NewAgent("agent-1", "node-1", state, clock, logger)_x000A__x000A_  - Optionally add one small test (not exhaustive) that:_x000A_    - Uses a `TestLogger` collecting messages._x000A_    - Verifies that a specific key event (e.g. `SendCreateEntry`) emits at least one log entry._x000A_    - This is mainly to guard against logger being accidentally nil or unused._x000A__x000A_## Acceptance criteria_x000A__x000A_- Logger abstraction:_x000A_  - A `Logger` interface exists in SBI code with `Debug`, `Info`, `Warn`, `Error` methods._x000A_  - `StdLogger` (default) and `NoopLogger` (for tests) are implemented._x000A_  - `NewCDPIServer` and `NewAgent` (or equivalent constructors) accept a `Logger` and default it if nil._x000A__x000A_- CDPI server logging:_x000A_  - `ReceiveRequests` and related methods log:_x000A_    - Agent Hello (with `agent_id`, `node_id`)._x000A_    - Reset handling (with `agent_id`, `old_token`, `new_token`)._x000A_    - Sent `CreateEntry`, `DeleteEntry`, and `Finalize` messages (with `agent_id`, `entry_id`, `when`, `type`, `request_id`, `seqno`, `token`)._x000A_    - Responses from agents (with `agent_id`, `request_id`, `status`)._x000A_    - Stream closure or errors (with `agent_id`, `err`)._x000A_  - Logs are structured via key/value pairs, not free-form concatenated strings._x000A__x000A_- Agent logging:_x000A_  - Agent lifecycle logs:_x000A_    - Start / stop events with `agent_id`, `node_id`._x000A_    - Hello and Reset RPCs where applicable._x000A_  - Schedule-related logs:_x000A_    - Receipt of `CreateEntry`, `DeleteEntry`, `Finalize` (with `agent_id`, `entry_id`, `when`, `type`, `seqno`, `token`)._x000A_    - Token mismatch cases logged as warnings (with expected vs actual token)._x000A_    - Scheduling of `ScheduledAction` into `EventScheduler`._x000A_    - Execution of actions (with success/failure, including `err` on failure)._x000A_  - Telemetry-related logs:_x000A_    - Telemetry ticks (DEBUG level)._x000A_    - `ExportMetrics` failures (WARN level)._x000A__x000A_- Cleanup:_x000A_  - Any previous `fmt.Printf` / ad-hoc logs in SBI code paths are either:_x000A_    - Replaced with structured logger calls, or_x000A_    - Removed if redundant._x000A_  - Tests compile and pass using `NoopLogger` or `TestLogger`._x000A__x000A_- Repository health:_x000A_  - `go build ./...` passes._x000A_  - `go test ./...` passes, including SBI-related tests._x000A_</S>
      <S N="State2">open</S>
    </MS>
  </Obj>
  <Obj RefId="1">
    <TNRef RefId="0" />
    <MS>
      <S N="Topic">Metrics</S>
      <I32 N="Issue1">181</I32>
      <S N="Title1">[Scope 4][Chunk 12] Add minimal SBI metrics counters for controller and agents</S>
      <S N="Body1">## Background_x000A__x000A_Chunk 12 is about **observability &amp; developer experience** for SBI. Logging gives you a narrative view of what’s happening, but it’s also useful to have **simple, in-process counters** so you can quickly inspect high-level behaviour:_x000A__x000A_- How many schedule entries were sent to agents?_x000A_- How many actions did agents actually execute?_x000A_- How many responses came back OK vs error?_x000A_- How many telemetry reports have been received?_x000A__x000A_These metrics don’t need to be exposed via NBI or Prometheus yet; they just need to exist as **lightweight counters** you can:_x000A__x000A_- Log at shutdown or on demand._x000A_- Inspect in tests and debug helpers._x000A_- Use as a first-pass sanity check that SBI is “alive”._x000A__x000A_This issue adds those **minimal metrics counters** for core SBI components: CDPI server, agents, and Telemetry server._x000A__x000A_## Goal_x000A__x000A_Introduce simple, concurrency-safe counters for SBI activity:_x000A__x000A_- On the **CDPI server**:_x000A_  - Number of `CreateEntry`, `DeleteEntry`, and `Finalize` messages sent to agents._x000A_  - Number of `Reset` and `Response` messages received from agents._x000A_- On the **Agent** side:_x000A_  - Number of scheduled actions executed (by type: beam, route, etc. if convenient)._x000A_- On the **Telemetry** side:_x000A_  - Number of `ExportMetrics` RPCs received._x000A_  - Total number of `InterfaceMetrics` processed._x000A__x000A_Expose these counters through small helper structs / methods so they can be:_x000A__x000A_- Incremented in hot paths with minimal overhead._x000A_- Dumped to logs or inspected by tests and future debug tools._x000A__x000A_## Where to look_x000A__x000A_- **CDPI server** (Chunk 5, controller side):_x000A__x000A_  - Something like: `internal/sbi/controller/cdpi_server.go`._x000A_  - Server type similar to:_x000A__x000A_        type CDPIServer struct {_x000A_            scheduling.UnimplementedControlDataPlaneInterfaceServer_x000A__x000A_            State    *simstate.ScenarioState_x000A_            Clock    sbi.EventScheduler_x000A__x000A_            agentsMu sync.RWMutex_x000A_            agents   map[string]*AgentHandle_x000A__x000A_            // Add metrics here_x000A_        }_x000A__x000A_- **Agent** implementation (Chunks 4, 7–8):_x000A__x000A_  - Under: `internal/sbi/agent/agent.go` (or similar)._x000A_  - Where you already:_x000A_    - Schedule actions from incoming CDPI messages._x000A_    - Execute actions via `execute(action *ScheduledAction)`._x000A__x000A_- **Telemetry server** (Chunk 6):_x000A__x000A_  - Under something like: `internal/sbi/telemetry/server.go`._x000A_  - `TelemetryServer.ExportMetrics` is the natural place to increment counters._x000A__x000A_- Any existing **debug / dump** or helper packages where a metrics dump function might live (to be used later in the “DumpAgentState” issue)._x000A__x000A_Search terms:_x000A__x000A_- `type CDPIServer struct`_x000A_- `type Agent struct`_x000A_- `type TelemetryServer struct`_x000A_- `ExportMetrics`_x000A_- `execute(action *ScheduledAction)`_x000A__x000A_## Tasks_x000A__x000A_### 1. Define a minimal metrics struct for SBI_x000A__x000A_Create a small package or file for SBI metrics, e.g. `internal/sbi/metrics.go`:_x000A__x000A_- Define per-component metrics types, for example:_x000A__x000A_      type CDPIMetrics struct {_x000A_          mu sync.Mutex_x000A__x000A_          CreateEntrySent   uint64_x000A_          DeleteEntrySent   uint64_x000A_          FinalizeSent      uint64_x000A_          ResetReceived     uint64_x000A_          ResponsesOK       uint64_x000A_          ResponsesError    uint64_x000A_      }_x000A__x000A_      type AgentMetrics struct {_x000A_          mu sync.Mutex_x000A__x000A_          ActionsExecutedTotal uint64_x000A_          BeamsUpdated         uint64_x000A_          BeamsDeleted         uint64_x000A_          RoutesInstalled      uint64_x000A_          RoutesDeleted        uint64_x000A_      }_x000A__x000A_      type TelemetryMetrics struct {_x000A_          mu sync.Mutex_x000A__x000A_          ExportCalls      uint64_x000A_          InterfaceSamples uint64_x000A_      }_x000A__x000A_Notes:_x000A__x000A_- Keep everything `uint64` for simplicity._x000A_- Use a `sync.Mutex` (or `sync.RWMutex`) for correctness; you can optimize later if needed._x000A_- Provide small helper methods to increment counters to keep call sites clean:_x000A__x000A_      func (m *CDPIMetrics) IncCreateEntrySent() {_x000A_          m.mu.Lock()_x000A_          m.CreateEntrySent++_x000A_          m.mu.Unlock()_x000A_      }_x000A__x000A_      // Similarly for other counters._x000A__x000A_### 2. Wire metrics into CDPIServer_x000A__x000A_Extend `CDPIServer`:_x000A__x000A_- Add a field:_x000A__x000A_      type CDPIServer struct {_x000A_          // existing fields..._x000A__x000A_          Metrics *CDPIMetrics_x000A_      }_x000A__x000A_- Ensure there is a constructor or init path that sets `Metrics` to a non-nil instance, e.g.:_x000A__x000A_      func NewCDPIServer(state *simstate.ScenarioState, clock sbi.EventScheduler) *CDPIServer {_x000A_          return &amp;CDPIServer{_x000A_              State:   state,_x000A_              Clock:   clock,_x000A_              agents:  make(map[string]*AgentHandle),_x000A_              Metrics: &amp;CDPIMetrics{},_x000A_          }_x000A_      }_x000A__x000A_- In methods that send controller→agent messages:_x000A__x000A_  - When building and enqueuing a `CreateEntryRequest`, call `Metrics.IncCreateEntrySent()`._x000A_  - Similarly for `DeleteEntry` and `Finalize`._x000A__x000A_- In the stream read loop (`ReceiveRequests`):_x000A__x000A_  - On `Reset` from agents, increment `Metrics.ResetReceived`._x000A_  - On `Response` from agents:_x000A_    - If status is OK → `Metrics.ResponsesOK++`._x000A_    - Otherwise → `Metrics.ResponsesError++`._x000A__x000A_Design note:_x000A__x000A_- Keep increments very small and local; don’t add heavy logging here (logging is a separate issue)._x000A__x000A_### 3. Wire metrics into Agent execution_x000A__x000A_Extend `Agent`:_x000A__x000A_- Add a metrics field:_x000A__x000A_      type Agent struct {_x000A_          // existing fields..._x000A__x000A_          Metrics *AgentMetrics_x000A_      }_x000A__x000A_- Ensure that when agents are constructed (e.g. in scenario startup wiring), `Metrics` is non-nil:_x000A__x000A_      func NewAgent(/* existing params */) *Agent {_x000A_          return &amp;Agent{_x000A_              // existing fields..._x000A_              Metrics: &amp;AgentMetrics{},_x000A_          }_x000A_      }_x000A__x000A_- In the `execute(action *ScheduledAction)` method (or equivalent):_x000A__x000A_  - At the top or after a successful state update, increment:_x000A__x000A_        a.Metrics.ActionsExecutedTotal++_x000A__x000A_  - Optionally increment per-type counters:_x000A__x000A_        switch action.Type {_x000A_        case ScheduledUpdateBeam:_x000A_            a.Metrics.BeamsUpdated++_x000A_        case ScheduledDeleteBeam:_x000A_            a.Metrics.BeamsDeleted++_x000A_        case ScheduledSetRoute:_x000A_            a.Metrics.RoutesInstalled++_x000A_        case ScheduledDeleteRoute:_x000A_            a.Metrics.RoutesDeleted++_x000A_        }_x000A__x000A_Notes:_x000A__x000A_- For now, counting on successful execution is enough; if you later add explicit failure paths, you can add separate “failed” counters._x000A__x000A_### 4. Wire metrics into TelemetryServer_x000A__x000A_Extend `TelemetryServer` (Chunk 6):_x000A__x000A_- Add a metrics field:_x000A__x000A_      type TelemetryServer struct {_x000A_          telemetry.UnimplementedTelemetryServiceServer_x000A__x000A_          Telemetry *TelemetryState_x000A_          Metrics   *TelemetryMetrics_x000A_      }_x000A__x000A_- Initialize `Metrics` in the constructor:_x000A__x000A_      func NewTelemetryServer(tstate *TelemetryState) *TelemetryServer {_x000A_          return &amp;TelemetryServer{_x000A_              Telemetry: tstate,_x000A_              Metrics:   &amp;TelemetryMetrics{},_x000A_          }_x000A_      }_x000A__x000A_- In `ExportMetrics`:_x000A__x000A_  - At the start, increment `Metrics.ExportCalls`._x000A_  - As you iterate over `req.InterfaceMetrics`:_x000A_    - After each processed entry (or once at the end), update `Metrics.InterfaceSamples`:_x000A__x000A_          func (m *TelemetryMetrics) AddInterfaceSamples(n int) {_x000A_              m.mu.Lock()_x000A_              m.InterfaceSamples += uint64(n)_x000A_              m.mu.Unlock()_x000A_          }_x000A__x000A_  - Call `Metrics.AddInterfaceSamples(len(req.InterfaceMetrics))`._x000A__x000A_### 5. Accessor / dump helpers_x000A__x000A_Provide simple read / snapshot methods so tests and debug code can inspect counters without racing:_x000A__x000A_- In `metrics.go`:_x000A__x000A_      type CDPIMetricsSnapshot struct {_x000A_          CreateEntrySent   uint64_x000A_          DeleteEntrySent   uint64_x000A_          FinalizeSent      uint64_x000A_          ResetReceived     uint64_x000A_          ResponsesOK       uint64_x000A_          ResponsesError    uint64_x000A_      }_x000A__x000A_      func (m *CDPIMetrics) Snapshot() CDPIMetricsSnapshot {_x000A_          m.mu.Lock()_x000A_          defer m.mu.Unlock()_x000A__x000A_          return CDPIMetricsSnapshot{_x000A_              CreateEntrySent: m.CreateEntrySent,_x000A_              DeleteEntrySent: m.DeleteEntrySent,_x000A_              FinalizeSent:    m.FinalizeSent,_x000A_              ResetReceived:   m.ResetReceived,_x000A_              ResponsesOK:     m.ResponsesOK,_x000A_              ResponsesError:  m.ResponsesError,_x000A_          }_x000A_      }_x000A__x000A_- Do the same pattern for `AgentMetrics` and `TelemetryMetrics`._x000A__x000A_These snapshots will be useful:_x000A__x000A_- In unit tests._x000A_- In a later “DumpAgentState” / debug endpoints issue._x000A__x000A_### 6. Basic unit tests for metrics_x000A__x000A_Add a small test file, e.g. `internal/sbi/metrics_test.go`:_x000A__x000A_- Tests should be simple and fast:_x000A__x000A_1. **CDPIMetrics increments**_x000A__x000A_   - Create a `CDPIMetrics`, call increment helpers (`IncCreateEntrySent`, etc.)._x000A_   - Call `Snapshot()` and assert the expected counts._x000A__x000A_2. **AgentMetrics increments**_x000A__x000A_   - Same pattern: increment fields, snapshot, and assert._x000A__x000A_3. **TelemetryMetrics increments**_x000A__x000A_   - Verify `ExportCalls` and `InterfaceSamples` increment correctly._x000A__x000A_Optionally, add very lightweight integration-style checks:_x000A__x000A_- In an existing CDPI server test, after simulating sending `CreateEntry`, check that `Metrics.CreateEntrySent` increased by 1._x000A_- In a telemetry server test, after calling `ExportMetrics` once with N interfaces, assert that `InterfaceSamples == N`._x000A__x000A_## Acceptance criteria_x000A__x000A_- **Metrics structs added:**_x000A_  - `CDPIMetrics`, `AgentMetrics`, and `TelemetryMetrics` exist under `internal/sbi` (or closely related package)._x000A_  - Each struct:_x000A_    - Uses a `sync.Mutex` or equivalent for concurrency safety._x000A_    - Encapsulates counters as `uint64` fields._x000A_    - Provides small, clear increment helpers._x000A__x000A_- **CDPI server:**_x000A_  - `CDPIServer` has a `Metrics *CDPIMetrics` field initialised in its constructor._x000A_  - Sending `CreateEntry`, `DeleteEntry`, and `Finalize` requests increments the relevant counters._x000A_  - Receiving `Reset` and `Response` messages updates the appropriate counters (OK vs error)._x000A__x000A_- **Agent:**_x000A_  - `Agent` has a `Metrics *AgentMetrics` field._x000A_  - Executing scheduled actions via `execute(action *ScheduledAction)` increments:_x000A_    - `ActionsExecutedTotal`._x000A_    - Per-type counters where appropriate (beams/routes)._x000A__x000A_- **Telemetry server:**_x000A_  - `TelemetryServer` has a `Metrics *TelemetryMetrics` field._x000A_  - Each `ExportMetrics` call increments `ExportCalls`._x000A_  - The number of `InterfaceMetrics` in requests is accumulated into `InterfaceSamples`._x000A__x000A_- **Snapshots / accessors:**_x000A_  - Each metrics struct provides a `Snapshot()` method (or equivalent) returning a copy of current counts._x000A_  - Snapshot methods are safe to call concurrently with increments._x000A__x000A_- **Tests:**_x000A_  - New unit tests cover:_x000A_    - Basic increment behaviour and snapshots for each metrics type._x000A_    - At least one CDPI/Telemetry path where counters change as expected._x000A_  - All tests pass via `go test ./...`._x000A__x000A_- **Repository health:**_x000A_  - `go build ./...` passes with the new metrics code._x000A_  - No significant logging or behavioural changes beyond adding counters and minimal metrics wiring._x000A_</S>
      <S N="State1">open</S>
      <I32 N="Issue2">182</I32>
      <S N="Title2">[Scope 4][Chunk 12] Add in-memory SBI metrics counters for CDPI, Agents, and Telemetry</S>
      <S N="Body2">## Background_x000A__x000A_Scope 4 now has:_x000A__x000A_- CDPI server and agents:_x000A_  - Agents receive scheduled actions (CreateEntry/DeleteEntry/Finalize/Reset)._x000A_  - Agents execute actions and send Responses back to the controller._x000A_- Telemetry:_x000A_  - `TelemetryService.ExportMetrics` on the controller side._x000A_  - Agent-side telemetry loop emitting `ExportMetricsRequest` periodically._x000A__x000A_Chunk 12 is about **observability &amp; developer experience**. 12.1 added structured logging for CDPI/agents (and possibly Telemetry). The next piece (12.2) is **lightweight in-memory metrics**:_x000A__x000A_- Simple counters that track “how much SBI is doing” without introducing heavy dependencies._x000A_- Purely internal (not exported via NBI yet)._x000A_- Usable in:_x000A_  - Unit tests (assert behaviour)._x000A_  - Ad-hoc debugging (dumping metrics to logs or a debug API)._x000A__x000A_Examples from the Scope 4 plan:_x000A__x000A_- `num_create_entry_sent`, `num_delete_entry_sent`._x000A_- `num_actions_executed`, `num_responses_ok`, `num_responses_error`._x000A_- `num_telemetry_reports`._x000A__x000A_This issue adds a small metrics container + instrumentation points in CDPI, Agent, and Telemetry paths._x000A__x000A_## Goal_x000A__x000A_Provide an in-memory metrics facility that:_x000A__x000A_- Tracks a small set of SBI counters (CDPI, Agent execution, Telemetry)._x000A_- Is concurrency-safe and cheap to update._x000A_- Is easy to query/dump for debugging and unit tests._x000A_- Does **not** introduce new external dependencies (stick to stdlib)._x000A__x000A_## Where to look_x000A__x000A_- CDPI server (controller side):_x000A__x000A_  - Under something like:_x000A__x000A_        internal/sbi/controller/cdpi_server.go_x000A__x000A_  - Where Create/Delete/Finalize are sent to agents and Responses are received._x000A__x000A_- Agent implementation:_x000A__x000A_  - Under:_x000A__x000A_        internal/sbi/agent/agent.go_x000A__x000A_  - Where actions are scheduled/executed and Responses are written to the stream._x000A__x000A_- Telemetry server and state:_x000A__x000A_  - Telemetry server:_x000A__x000A_        internal/sbi/telemetry_server.go_x000A_        // or similar_x000A__x000A_  - Telemetry state:_x000A__x000A_        internal/sim/state/telemetry_state.go_x000A_        // or sim/state/metrics.go, depending on how you structured Chunk 6._x000A__x000A_- Any existing “debug / stats” helpers:_x000A__x000A_  - Search for:_x000A_    - `Stats`, `Metrics`, `Counters`, `DebugDump`, `DumpState`._x000A__x000A_## Tasks_x000A__x000A_### 1. Define a minimal SBI metrics struct_x000A__x000A_Add a small metrics container in an appropriate package, for example:_x000A__x000A_- New file:_x000A__x000A_      internal/sbi/metrics.go_x000A__x000A_Define something like:_x000A__x000A_- Per-process SBI metrics:_x000A__x000A_      type SBIMetrics struct {_x000A_          mu sync.Mutex_x000A__x000A_          // CDPI → Agent commands_x000A_          NumCreateEntrySent   uint64_x000A_          NumDeleteEntrySent   uint64_x000A_          NumFinalizeSent      uint64_x000A__x000A_          // Agent-side execution_x000A_          NumActionsExecuted   uint64_x000A__x000A_          // Agent → CDPI responses_x000A_          NumResponsesOK       uint64_x000A_          NumResponsesError    uint64_x000A__x000A_          // Telemetry_x000A_          NumTelemetryReports  uint64_x000A_      }_x000A__x000A_Add helpers:_x000A__x000A_- Constructor:_x000A__x000A_      func NewSBIMetrics() *SBIMetrics_x000A__x000A_- Increment helpers (so callers don’t touch fields directly):_x000A__x000A_      func (m *SBIMetrics) IncCreateEntrySent()_x000A_      func (m *SBIMetrics) IncDeleteEntrySent()_x000A_      func (m *SBIMetrics) IncFinalizeSent()_x000A_      func (m *SBIMetrics) IncActionsExecuted()_x000A_      func (m *SBIMetrics) IncResponsesOK()_x000A_      func (m *SBIMetrics) IncResponsesError()_x000A_      func (m *SBIMetrics) IncTelemetryReports()_x000A__x000A_- Snapshot:_x000A__x000A_      type SBIMetricsSnapshot struct {_x000A_          NumCreateEntrySent  uint64_x000A_          NumDeleteEntrySent  uint64_x000A_          NumFinalizeSent     uint64_x000A_          NumActionsExecuted  uint64_x000A_          NumResponsesOK      uint64_x000A_          NumResponsesError   uint64_x000A_          NumTelemetryReports uint64_x000A_      }_x000A__x000A_      func (m *SBIMetrics) Snapshot() SBIMetricsSnapshot_x000A__x000A_Notes:_x000A__x000A_- Use a simple `sync.Mutex` (or `sync.RWMutex`) to keep this trivial and safe._x000A_- Keep the API intentionally small and boring; this is internal infra._x000A__x000A_### 2. Wire SBIMetrics into CDPI server_x000A__x000A_Update the CDPI server struct (controller side) to carry a metrics pointer:_x000A__x000A_- In `internal/sbi/controller/cdpi_server.go` (or equivalent):_x000A__x000A_      type CDPIServer struct {_x000A_          scheduling.UnimplementedControlDataPlaneInterfaceServer_x000A__x000A_          State    *simstate.ScenarioState_x000A_          Clock    sbi.EventScheduler_x000A__x000A_          agentsMu sync.RWMutex_x000A_          agents   map[string]*AgentHandle_x000A__x000A_          Metrics  *sbi.SBIMetrics  // new field_x000A_      }_x000A__x000A_Design notes:_x000A__x000A_- `Metrics` can be optional:_x000A_  - If `nil`, skip increments._x000A_  - This keeps tests / callers flexible._x000A_- Prefer injecting `Metrics` at construction time (e.g. via `NewCDPIServer(...)`)._x000A__x000A_Instrumentation points:_x000A__x000A_- In controller → agent send paths (where you already build messages):_x000A__x000A_      func (s *CDPIServer) SendCreateEntry(...) error {_x000A_          // On success:_x000A_          if s.Metrics != nil {_x000A_              s.Metrics.IncCreateEntrySent()_x000A_          }_x000A_      }_x000A__x000A_      func (s *CDPIServer) SendDeleteEntry(...) error {_x000A_          if s.Metrics != nil {_x000A_              s.Metrics.IncDeleteEntrySent()_x000A_          }_x000A_      }_x000A__x000A_      func (s *CDPIServer) SendFinalize(...) error {_x000A_          if s.Metrics != nil {_x000A_              s.Metrics.IncFinalizeSent()_x000A_          }_x000A_      }_x000A__x000A_- In agent → controller receive path:_x000A__x000A_  - When you handle Responses in `ReceiveRequests(...)`:_x000A__x000A_        switch msg := incoming.GetAgentToController().(type) {_x000A_        case *scheduling.ReceiveRequestsMessageFromAgent_Response:_x000A_            // existing status handling..._x000A_            if s.Metrics != nil {_x000A_                if msg.Response.Status == scheduling.Status_STATUS_OK { // adjust to real enum_x000A_                    s.Metrics.IncResponsesOK()_x000A_                } else {_x000A_                    s.Metrics.IncResponsesError()_x000A_                }_x000A_            }_x000A_        }_x000A__x000A_### 3. Wire SBIMetrics into Agent execution_x000A__x000A_Extend the Agent struct to accept a metrics pointer:_x000A__x000A_- In `internal/sbi/agent/agent.go`:_x000A__x000A_      type Agent struct {_x000A_          AgentID   string_x000A_          NodeID    string_x000A_          State     *simstate.ScenarioState_x000A_          Scheduler sbi.EventScheduler_x000A__x000A_          // SBI_x000A_          TelemetryClient telemetry.TelemetryServiceClient_x000A_          Stream          scheduling.ControlDataPlaneInterface_ReceiveRequestsClient_x000A__x000A_          // Scheduling / pending entries..._x000A_          // ..._x000A__x000A_          Metrics *sbi.SBIMetrics // optional shared pointer from controller or global_x000A_      }_x000A__x000A_Instrumentation point:_x000A__x000A_- In the method that executes a scheduled action, e.g.:_x000A__x000A_      func (a *Agent) execute(action *ScheduledAction) {_x000A_          // existing switch on action.Type, calling ScenarioState.ApplyXXX..._x000A__x000A_          if a.Metrics != nil {_x000A_              a.Metrics.IncActionsExecuted()_x000A_          }_x000A__x000A_          // build &amp; send Response back to controller..._x000A_      }_x000A__x000A_Notes:_x000A__x000A_- If you already have multiple execution paths (beam, route, etc.), instrument once per actual “action run” (not per helper call)._x000A__x000A_### 4. Wire SBIMetrics into TelemetryService_x000A__x000A_Extend Telemetry server struct:_x000A__x000A_- In `internal/sbi/telemetry_server.go`:_x000A__x000A_      type TelemetryServer struct {_x000A_          telemetry.UnimplementedTelemetryServiceServer_x000A__x000A_          Telemetry *simstate.TelemetryState_x000A_          Metrics   *sbi.SBIMetrics // new, optional_x000A_      }_x000A__x000A_Instrumentation point:_x000A__x000A_- In `ExportMetrics`:_x000A__x000A_      func (s *TelemetryServer) ExportMetrics(ctx context.Context, req *telemetry.ExportMetricsRequest) (*telemetry.ExportMetricsResponse, error) {_x000A_          // existing: translate &amp; update TelemetryState..._x000A__x000A_          if s.Metrics != nil {_x000A_              s.Metrics.IncTelemetryReports()_x000A_          }_x000A__x000A_          return &amp;telemetry.ExportMetricsResponse{}, nil_x000A_      }_x000A__x000A_### 5. Provide a simple debug dump helper_x000A__x000A_Add a small helper that renders the metrics snapshot as a string for logs / debug UIs._x000A__x000A_- In `internal/sbi/metrics.go` (same file as SBIMetrics):_x000A__x000A_      func (m *SBIMetrics) String() string {_x000A_          snap := m.Snapshot()_x000A_          return fmt.Sprintf("SBI metrics: create=%d delete=%d finalize=%d executed=%d resp_ok=%d resp_err=%d telemetry_reports=%d",_x000A_              snap.NumCreateEntrySent,_x000A_              snap.NumDeleteEntrySent,_x000A_              snap.NumFinalizeSent,_x000A_              snap.NumActionsExecuted,_x000A_              snap.NumResponsesOK,_x000A_              snap.NumResponsesError,_x000A_              snap.NumTelemetryReports,_x000A_          )_x000A_      }_x000A__x000A_Optional:_x000A__x000A_- Hook this into any existing “dump state” / debug endpoints (or leave for Chunk 12.3 dedicated debug-dump issue)._x000A__x000A_### 6. Unit tests_x000A__x000A_Add tests that verify counters move as expected, in at least these places:_x000A__x000A_1. **CDPI server send paths**_x000A__x000A_   - File: `internal/sbi/controller/cdpi_server_metrics_test.go` (or folded into existing tests)._x000A_   - Use a `CDPIServer` with:_x000A_     - `Metrics = NewSBIMetrics()`._x000A_     - Fake `AgentHandle` / outgoing channel to avoid real network._x000A_   - Call:_x000A_     - `SendCreateEntry`, `SendDeleteEntry`, `SendFinalize`._x000A_   - Assert:_x000A_     - `Metrics.Snapshot()` shows the expected increments._x000A__x000A_2. **CDPI server Response handling**_x000A__x000A_   - Simulate incoming Responses with:_x000A_     - `Status = OK`._x000A_     - `Status = ERROR` (or non-OK)._x000A_   - Assert:_x000A_     - `NumResponsesOK` and `NumResponsesError` are incremented correctly._x000A__x000A_3. **Agent execution**_x000A__x000A_   - File: `internal/sbi/agent/agent_metrics_test.go`._x000A_   - Create an `Agent` with:_x000A_     - A fake `ScenarioState` that accepts actions without error._x000A_     - `Metrics = NewSBIMetrics()`._x000A_   - Call `agent.execute(&amp;ScheduledAction{...})` once or multiple times._x000A_   - Assert:_x000A_     - `NumActionsExecuted` equals number of executions._x000A__x000A_4. **Telemetry server**_x000A__x000A_   - File: `internal/sbi/telemetry_server_metrics_test.go`._x000A_   - Create a `TelemetryServer` with:_x000A_     - `TelemetryState` (in-memory)._x000A_     - `Metrics = NewSBIMetrics()`._x000A_   - Call `ExportMetrics` with a request containing one or more `InterfaceMetrics`._x000A_   - Assert:_x000A_     - `NumTelemetryReports` incremented by 1 per call (or per request, depending on design; document your choice)._x000A__x000A_5. **SBIMetrics concurrency/snapshot sanity**_x000A__x000A_   - Optional but nice:_x000A_     - Use a small test that calls various `Inc*` methods from multiple goroutines._x000A_     - At the end, call `Snapshot()` and ensure the counts match the sum of increments._x000A__x000A_## Acceptance criteria_x000A__x000A_- `SBIMetrics` type exists with:_x000A_  - Concurrency-safe increment helpers._x000A_  - `Snapshot()` method returning a plain struct._x000A_  - `String()` method for human-readable debug dumps._x000A__x000A_- CDPI server:_x000A_  - Has an optional `Metrics *SBIMetrics` field._x000A_  - Increments:_x000A_    - `NumCreateEntrySent` when a CreateEntry is successfully queued/sent._x000A_    - `NumDeleteEntrySent` when a DeleteEntry is successfully queued/sent._x000A_    - `NumFinalizeSent` when a FinalizeRequest is sent._x000A_    - `NumResponsesOK` / `NumResponsesError` when Responses are received from agents._x000A__x000A_- Agents:_x000A_  - Have an optional `Metrics *SBIMetrics` field._x000A_  - Increment `NumActionsExecuted` once per successfully executed scheduled action._x000A__x000A_- Telemetry server:_x000A_  - Has an optional `Metrics *SBIMetrics` field._x000A_  - Increments `NumTelemetryReports` on each `ExportMetrics` call._x000A__x000A_- All instrumentation is **best-effort**:_x000A_  - If `Metrics == nil`, behaviour is unchanged._x000A_  - Metrics updates must not affect control-path correctness (no panics, no blocking on slow paths)._x000A__x000A_- Tests:_x000A_  - New tests cover:_x000A_    - CDPI send-side counters._x000A_    - CDPI response counters._x000A_    - Agent execution counter._x000A_    - Telemetry reports counter._x000A_  - All tests pass via `go test ./...`._x000A__x000A_- Repository health:_x000A_  - `go build ./...` passes with metrics types and instrumentation in place._x000A_  - No new external dependencies are introduced for metrics._x000A_</S>
      <S N="State2">open</S>
    </MS>
  </Obj>
  <Obj RefId="2">
    <TNRef RefId="0" />
    <MS>
      <S N="Topic">Static Routes</S>
      <I32 N="Issue1">161</I32>
      <S N="Title1">[Scope 4][Chunk 8] Implement static route scheduling for single-hop links</S>
      <S N="Body1">## Background_x000A__x000A_By this point in **Scope 4 / Chunk 8** you have:_x000A__x000A_- Core SBI + sim plumbing from earlier chunks:_x000A_  - `ScenarioState` with:_x000A_    - Nodes, interfaces, and links (Scope 2)._x000A_    - Beam/routing helpers from Chunk 2 (`InstallRoute`, `RemoveRoute`, etc.)._x000A_  - A working `CDPIServer` (Chunk 5) that can send `CreateEntry` / `DeleteEntry` messages._x000A_  - Agents that:_x000A_    - Maintain a local schedule (`ScheduledAction` queue)._x000A_    - Execute `ScheduledSetRoute` / `ScheduledDeleteRoute` by calling `ScenarioState.InstallRoute` / `RemoveRoute`._x000A_  - Telemetry path from agents to controller (Chunk 6)._x000A__x000A_- A **Scheduler** (Chunk 8.1) skeleton in `internal/sbi/controller`:_x000A_  - Knows about:_x000A_    - `ScenarioState` (read-only view of nodes/links)._x000A_    - `EventScheduler` / sim clock._x000A_    - `CDPIServer` for sending scheduled actions to agents._x000A_  - And an initial issue for **link-driven beam scheduling** (UpdateBeam/DeleteBeam)._x000A__x000A_What’s still missing is the **routing side** of scheduling for simple, single-hop connectivity:_x000A__x000A_- When a point-to-point link between nodes A and B is “in view” and schedulable:_x000A_  - The controller should automatically install **static routes** on both endpoints, so that:_x000A_    - A has a route to B via the interface on that link._x000A_    - B has a route to A via its interface on that link._x000A_- When the link leaves view / is torn down:_x000A_  - The controller should schedule **route deletion** on both nodes at the right sim times._x000A__x000A_This issue implements that minimal static routing behavior so that, whenever a link is activated by the scheduler, both endpoints get symmetric single-hop routes installed and later removed._x000A__x000A_## Goal_x000A__x000A_Teach the **controller Scheduler** to:_x000A__x000A_- For each **single-hop link interval** `[T_on, T_off]` between nodes A and B:_x000A_  - Schedule `SetRoute` actions on A and B at (or shortly after) `T_on`._x000A_  - Schedule `DeleteRoute` actions on A and B at `T_off`._x000A_- Use the same per-agent scheduling path as beams:_x000A_  - Build `ScheduledAction` entries (`ScheduledSetRoute` / `ScheduledDeleteRoute`)._x000A_  - Send them via `CDPIServer.SendCreateEntry` / `SendDeleteEntry`._x000A_- Keep the behavior:_x000A_  - Deterministic._x000A_  - Easy to test (unit tests with in-memory `ScenarioState` + fake `CDPIServer`)._x000A__x000A_This is **single-hop only** and intentionally naive; multi-hop path routing and ServiceRequest-aware routing come later._x000A__x000A_## Where to look_x000A__x000A_Scheduler and controller:_x000A__x000A_- `internal/sbi/controller`:_x000A_  - `scheduler.go` (or equivalent):_x000A_    - `type Scheduler struct { ... }`_x000A_    - Methods like:_x000A_      - `func (s *Scheduler) RunOnce(...) error`_x000A_      - Or any `PlanScheduleForScenario(...)` / `PlanForLink(...)` helpers from the beam-scheduling issue._x000A__x000A_CDPI / scheduled actions:_x000A__x000A_- `internal/sbi/controller/cdpi_server.go` (or similar):_x000A_  - `CDPIServer` with:_x000A_    - `SendCreateEntry(agentID string, action *ScheduledAction) error`_x000A_    - `SendDeleteEntry(agentID, entryID string) error`_x000A_- `internal/sbi` or shared types:_x000A_  - `type ScheduledActionType` with values like:_x000A_    - `ScheduledSetRoute`_x000A_    - `ScheduledDeleteRoute`_x000A_  - `type ScheduledAction struct { ... When time.Time; Type ScheduledActionType; Route *RouteEntry; ... }`_x000A__x000A_ScenarioState / routing:_x000A__x000A_- `internal/sim/state` (or equivalent):_x000A_  - `ScenarioState` methods for routing, from earlier chunks:_x000A_    - `InstallRoute(nodeID string, route RouteEntry) error`_x000A_    - `RemoveRoute(nodeID, destCIDR string) error`_x000A_- Node / route model (Scope 4 Chunk 0 + 2):_x000A_  - `type RouteEntry struct { DestinationCIDR, NextHopNodeID, OutInterfaceID string }`_x000A_  - Routing storage on `NetworkNode` or in a routing helper._x000A__x000A_Link + interface info:_x000A__x000A_- Wherever links and interfaces are stored:_x000A_  - API(s) to list:_x000A_    - Potential links between nodes._x000A_    - The interfaces at each endpoint._x000A_    - The time intervals when a link is “in view” / schedulable._x000A_- Search terms:_x000A_  - `RouteEntry`_x000A_  - `InstallRoute`_x000A_  - `RemoveRoute`_x000A_  - `Scheduler`_x000A_  - `ScheduledSetRoute`_x000A_  - `ScheduledDeleteRoute`_x000A__x000A_## Tasks_x000A__x000A_### 1. Decide route semantics for single-hop links_x000A__x000A_Define a minimal, consistent policy for single-hop static routes:_x000A__x000A_- For a link between nodes `A` and `B` with endpoint interfaces `ifA` and `ifB`:_x000A_  - On link activation:_x000A_    - On node `A`:_x000A_      - Install a route whose:_x000A_        - `DestinationCIDR` targets node `B` (e.g. a per-node “/32” CIDR or a node-specific prefix)._x000A_        - `NextHopNodeID` is `B`._x000A_        - `OutInterfaceID` is `ifA`._x000A_    - On node `B`:_x000A_      - Install a symmetric route targeting node `A` via `ifB`._x000A_  - On link deactivation:_x000A_    - Remove those routes on both nodes using the same `DestinationCIDR` convention._x000A__x000A_Design notes:_x000A__x000A_- Keep it simple:_x000A_  - If you already have a “node-level” destination representation (e.g. `B` → `B/32`), reuse it._x000A_  - If not, define a helper such as:_x000A_    - `func NodeDestCIDR(nodeID string) string`_x000A_- For now, do **not** try to handle overlapping routes, priorities, or metrics._x000A__x000A_### 2. Extend Scheduler to generate route actions from link intervals_x000A__x000A_In the Scheduler implementation (likely the same place you implemented beam scheduling):_x000A__x000A_1. Identify single-hop links and their intervals:_x000A__x000A_   - Reuse the same discovery logic as beam scheduling:_x000A_     - For each link `L` between nodes A and B:_x000A_       - Determine its “in view” intervals `[T_on, T_off]`._x000A_   - Skip:_x000A_     - Links where you cannot unambiguously identify both endpoint node IDs and interface IDs._x000A_     - Links that are already covered by more advanced logic (for now, assume none)._x000A__x000A_2. For each interval `[T_on, T_off]`:_x000A__x000A_   - Construct internal `RouteEntry` structs:_x000A_     - `routeAtoB` for node A._x000A_     - `routeBtoA` for node B._x000A__x000A_   - Build `ScheduledAction` entries:_x000A__x000A_     - At time `T_on` (or `T_on - smallLead`, clamped to `&gt;= now`):_x000A__x000A_       - For node A → route to B:_x000A__x000A_         - `Type: ScheduledSetRoute`_x000A_         - `When: T_on` (or `T_on - lead` if you want route before beams)._x000A_         - `Route: routeAtoB`_x000A_         - `AgentID: agent controlling node A`_x000A__x000A_       - For node B → route to A:_x000A__x000A_         - `Type: ScheduledSetRoute`_x000A_         - `When: T_on`_x000A_         - `Route: routeBtoA`_x000A_         - `AgentID: agent controlling node B`_x000A__x000A_     - At time `T_off`:_x000A__x000A_       - For node A:_x000A__x000A_         - `Type: ScheduledDeleteRoute`_x000A_         - `When: T_off`_x000A_         - Enough data in `Route` (e.g. `DestinationCIDR`) or action metadata to allow the agent to remove the correct route._x000A__x000A_       - For node B: similarly._x000A__x000A_3. Use coherent `EntryID`s:_x000A__x000A_   - For example:_x000A_     - `"route:A-&gt;B:link:LID"`_x000A_     - `"route:B-&gt;A:link:LID"`_x000A_   - So that:_x000A_     - They’re stable per link interval._x000A_     - You can refer back to them if you later add explicit DeleteEntry behavior._x000A__x000A_### 3. Wire route actions into CDPI scheduling_x000A__x000A_For each `ScheduledAction` created in step 2:_x000A__x000A_- Map to the correct **agent**:_x000A__x000A_  - Decide how to go from `nodeID` to `agentID`:_x000A_    - Often 1:1 mapping, e.g. `agentID == nodeID` or via a lookup table maintained in the controller._x000A_  - If no agent exists for a node:_x000A_    - Log and skip (do not panic)._x000A__x000A_- Send to agent via `CDPIServer`:_x000A__x000A_  - For create:_x000A__x000A_    - Use `SendCreateEntry(agentID, action)`:_x000A_      - It will assign `request_id`, `seqno`, `schedule_manipulation_token`._x000A_      - It will enqueue a `CreateEntryRequest` on the agent stream._x000A__x000A_  - For delete:_x000A__x000A_    - Either:_x000A_      - Schedule `ScheduledDeleteRoute` with its own `EntryID` and use `SendCreateEntry` (if you treat delete as a separate scheduled action in the agent)._x000A_      - Or:_x000A_        - Use `SendDeleteEntry(agentID, entryID)` for the corresponding set-route action if your CDPI semantics are “delete the scheduled set-route event”._x000A_    - Pick one pattern and stick to it; document your choice in a small comment on `ScheduledAction` / scheduler._x000A__x000A_Design notes:_x000A__x000A_- Keep the same style as beam scheduling:_x000A_  - If beams used `ScheduledUpdateBeam` + symmetric `ScheduledDeleteBeam`, mirror it with routes._x000A_- Ensure actions are only scheduled once per link interval (no duplicates on repeated `RunOnce`)._x000A__x000A_### 4. Add unit tests for route scheduling_x000A__x000A_In `internal/sbi/controller/scheduler_test.go` (or a new file such as `scheduler_routes_test.go`):_x000A__x000A_1. Test: single link → symmetric routes_x000A__x000A_   - Setup:_x000A_     - In-memory `ScenarioState` with:_x000A_       - Node `A` and node `B`._x000A_       - A single potential link between them with:_x000A_         - Known in-view interval `[T_on, T_off]`._x000A_         - Known interface IDs (`ifA`, `ifB`)._x000A_     - Fake `CDPIServer` that:_x000A_       - Captures calls to `SendCreateEntry` / `SendDeleteEntry`._x000A_   - Run:_x000A_     - Call the scheduler’s method that plans link-based routes (`RunOnce` or dedicated helper)._x000A_   - Assert:_x000A_     - Two `ScheduledSetRoute` actions:_x000A_       - One for `A` with `RouteEntry` targeting `B`._x000A_       - One for `B` targeting `A`._x000A_       - `When` ≈ `T_on` (or `T_on - lead`, as designed)._x000A_     - Two `ScheduledDeleteRoute` actions for the same node pairs at `T_off`._x000A__x000A_2. Test: route + beam coordination (sanity)_x000A__x000A_   - With both beam and route scheduling enabled:_x000A_     - Ensure that for a link interval, you get:_x000A_       - `UpdateBeam` + `SetRoute` events._x000A_       - `DeleteBeam` + `DeleteRoute` events._x000A_   - Assert at least that:_x000A_     - Route events are not created without their corresponding link interval._x000A_     - No duplicated route events._x000A__x000A_3. Test: no interfaces / malformed link_x000A__x000A_   - Scenario with a link missing interface IDs or node IDs._x000A_   - Run scheduler._x000A_   - Assert:_x000A_     - No route actions are scheduled._x000A_     - Scheduler does not panic._x000A__x000A_4. Test: agent mapping failure_x000A__x000A_   - Scenario where nodes exist but the mapping `nodeID → agentID` fails (e.g. missing agent)._x000A_   - Run scheduler._x000A_   - Assert:_x000A_     - No calls to `SendCreateEntry`._x000A_     - A warning or error is logged (optional, depending on your logging strategy)._x000A__x000A_## Acceptance criteria_x000A__x000A_- Scheduler behavior:_x000A__x000A_  - For each single-hop link with a known in-view interval `[T_on, T_off]`:_x000A_    - Schedules `ScheduledSetRoute` actions on **both endpoints** at or before `T_on`._x000A_    - Schedules corresponding route deletions (`ScheduledDeleteRoute` or equivalent) at `T_off`._x000A_  - Route entries:_x000A_    - Use a consistent `DestinationCIDR` scheme for node-level reachability._x000A_    - Set `NextHopNodeID` to the remote node and `OutInterfaceID` to the local interface on that link._x000A__x000A_- CDPI integration:_x000A__x000A_  - Scheduler uses `CDPIServer` to send route actions:_x000A_    - `SendCreateEntry` for route installation._x000A_    - Either `SendCreateEntry` with delete-type actions, or `SendDeleteEntry` targeting set-route actions; behavior is clearly implemented and documented._x000A_  - Actions are mapped to the correct agent based on node/agent mapping._x000A_  - No duplicate scheduling of the same route for a given link interval._x000A__x000A_- ScenarioState interaction:_x000A__x000A_  - When agents execute scheduled route actions:_x000A_    - `InstallRoute` is invoked with the `RouteEntry` provided by the scheduler._x000A_    - `RemoveRoute` is invoked on route deletion._x000A_  - Resulting per-node route tables reflect:_x000A_    - Symmetric single-hop routes while a link is active._x000A_    - No leftover routes after link deactivation._x000A__x000A_- Tests:_x000A__x000A_  - Scheduler unit tests cover:_x000A_    - Single link → symmetric route scheduling._x000A_    - Combined beam + route scheduling for consistency._x000A_    - Handling of malformed links / missing interfaces without panics._x000A_    - Handling of missing agents without panics._x000A_  - All new tests pass via `go test ./...`._x000A__x000A_- Repository health:_x000A__x000A_  - `go build ./...` passes after adding route scheduling._x000A_  - No change to public NBI behavior yet; this is purely internal controller scheduling logic for Scope 4._x000A_</S>
      <S N="State1">open</S>
      <I32 N="Issue2">162</I32>
      <S N="Title2">[Scope 4][Chunk 8] Add static single-hop routes based on link availability in Scheduler</S>
      <S N="Body2">## Background_x000A__x000A_By the time you reach this issue in **Chunk 8**, you should already have:_x000A__x000A_- A controller-side **Scheduler** type (non-gRPC) under something like `internal/sbi/controller`:_x000A_  - Holds a reference to `ScenarioState`._x000A_  - Has access to an `EventScheduler` / sim clock._x000A_  - Knows how to talk to `CDPIServer` via helpers like `SendCreateEntry` / `SendDeleteEntry`._x000A_- A basic **link-driven beam scheduling** implementation:_x000A_  - For each potential link with known "in view" intervals `[T_on, T_off]`, the scheduler:_x000A_    - Schedules an `UpdateBeam` `CreateEntry` near `T_on` for the satellite-side agent._x000A_    - Schedules a `DeleteBeam` `CreateEntry` at `T_off`._x000A__x000A_What’s still missing is the **static routing side** described in the Scope 4 plan:_x000A__x000A_- When a single-hop link is "on", both endpoints should have simple **static routes** installed pointing at each other._x000A_- When the link goes "off", those routes should be removed._x000A_- This is still **mechanism only** (no multi-hop pathfinding yet) but gives basic reachability for later scopes._x000A__x000A_This issue teaches the Scheduler to generate **SetRoute/DeleteRoute** scheduled actions in sync with link on/off intervals, using the existing per-node routing table support from Scope 4 Chunk 0 / 2._x000A__x000A_## Goal_x000A__x000A_Extend the controller Scheduler so that for each single-hop link interval `[T_on, T_off]`:_x000A__x000A_- At (or just before) `T_on`:_x000A_  - Schedule `SetRoute` actions on **both endpoints**:_x000A_    - Node A: add route `dest=B` via interface to B._x000A_    - Node B: add route `dest=A` via interface to A._x000A_- At `T_off`:_x000A_  - Schedule `DeleteRoute` for the corresponding `dest=B` / `dest=A` entries._x000A__x000A_Key properties:_x000A__x000A_- Uses the existing route table model (e.g. `RouteEntry`) and ScenarioState helpers `InstallRoute` / `RemoveRoute`._x000A_- Uses `ScheduledAction.Type` values like `ScheduledSetRoute` / `ScheduledDeleteRoute`._x000A_- Uses the same **per-agent CDPI flow** as beam scheduling (`CreateEntryRequest` containing SetRoute/DeleteRoute payloads)._x000A_- Keeps logic simple and deterministic; it does **not** attempt multi-hop routing yet (that comes with ServiceRequests in a later issue)._x000A__x000A_## Where to look_x000A__x000A_Scheduler implementation (Chunk 8 base):_x000A__x000A_- Likely under:_x000A__x000A_      internal/sbi/controller/scheduler.go_x000A__x000A_- Expected types:_x000A__x000A_      type Scheduler struct {_x000A_          State *simstate.ScenarioState_x000A_          Clock sbi.EventScheduler_x000A_          CDPI  *CDPIServer_x000A_          // maybe other fields (config, logger, etc.)_x000A_      }_x000A__x000A_- Existing methods (from prior Chunk 8 issue):_x000A__x000A_      func (s *Scheduler) ScheduleBeamsForLinks(...) { ... }_x000A_      func (s *Scheduler) RunOnce(...) error_x000A_      // or similar entrypoints_x000A__x000A_ScheduledAction model (Chunk 2 definitions):_x000A__x000A_- Somewhere under `internal/sbi` or `internal/sbi/types`:_x000A__x000A_      type ScheduledActionType int_x000A__x000A_      const (_x000A_          ScheduledUpdateBeam ScheduledActionType = iota_x000A_          ScheduledDeleteBeam_x000A_          ScheduledSetRoute_x000A_          ScheduledDeleteRoute_x000A_          ScheduledSetSrPolicy_x000A_          ScheduledDeleteSrPolicy_x000A_      )_x000A__x000A_      type ScheduledAction struct {_x000A_          EntryID   string_x000A_          When      time.Time_x000A_          Type      ScheduledActionType_x000A_          RequestID string_x000A_          SeqNo     int64_x000A_          Token     string_x000A_          Beam      *BeamSpec_x000A_          Route     *RouteEntry_x000A_          SrPolicy  *SrPolicySpec_x000A_      }_x000A__x000A_Route model and ScenarioState helpers (Chunks 0 / 2):_x000A__x000A_- Per-node routing fields, e.g. in `model.NetworkNode` or similar:_x000A__x000A_      type RouteEntry struct {_x000A_          DestinationCIDR string_x000A_          NextHopNodeID   string_x000A_          OutInterfaceID  string_x000A_      }_x000A__x000A_- ScenarioState routing helpers:_x000A__x000A_      func (s *ScenarioState) InstallRoute(nodeID string, route RouteEntry) error_x000A_      func (s *ScenarioState) RemoveRoute(nodeID, destCIDR string) error_x000A__x000A_Link model / connectivity info:_x000A__x000A_- Types that represent links and their endpoints, something like:_x000A__x000A_      type NetworkLink struct {_x000A_          LinkID      string_x000A_          NodeAID     string_x000A_          InterfaceA  string_x000A_          NodeBID     string_x000A_          InterfaceB  string_x000A_          // maybe capacity, in-view intervals, etc._x000A_      }_x000A__x000A_- Helper(s) to get **in-view intervals** or potential links:_x000A__x000A_      func (s *ScenarioState) ListPotentialLinks() []NetworkLink_x000A_      func (s *ScenarioState) GetLinkVisibility(linkID string) []VisibilityInterval_x000A__x000A_      type VisibilityInterval struct {_x000A_          Start time.Time_x000A_          End   time.Time_x000A_      }_x000A__x000A_CDPI helpers (from Chunk 5):_x000A__x000A_- On `CDPIServer` (or a helper wrapping it):_x000A__x000A_      func (s *CDPIServer) SendCreateEntry(agentID string, action *ScheduledAction) error_x000A_      func (s *CDPIServer) SendDeleteEntry(agentID, entryID string) error_x000A__x000A_You’ll reuse these to push route-related `CreateEntryRequest`s to agents._x000A__x000A_Search terms:_x000A__x000A_- `Scheduler struct`_x000A_- `ScheduledAction`_x000A_- `ScheduledSetRoute`_x000A_- `RouteEntry`_x000A_- `InstallRoute`_x000A_- `NetworkLink`_x000A_- `VisibilityInterval`_x000A__x000A_## Tasks_x000A__x000A_### 1. Decide how to derive route destinations for single-hop links_x000A__x000A_You need a consistent rule for what **destination** each static route should represent._x000A__x000A_A simple scheme:_x000A__x000A_- For each link between nodes A and B:_x000A_  - On node A, install a route `dest=B` with a `DestinationCIDR` that represents "node B"._x000A_  - On node B, install a route `dest=A`._x000A__x000A_Depending on your model, this might be:_x000A__x000A_- Just a synthetic `/32` or `/128` per node:_x000A__x000A_      route := RouteEntry{_x000A_          DestinationCIDR: fmt.Sprintf("%s/32", destNodeIP), // or some node ID → CIDR mapping_x000A_          NextHopNodeID:   destNodeID,_x000A_          OutInterfaceID:  ifaceID,_x000A_      }_x000A__x000A_- Or, if you don’t have real IP addresses yet:_x000A__x000A_  - Use a placeholder `DestinationCIDR` that your routing layer understands (e.g. `"node:B"`), but be consistent._x000A__x000A_**Design note:** For Scope 4, it’s acceptable to:_x000A__x000A_- Treat `DestinationCIDR` as an opaque key like `"node:&lt;ID&gt;"`._x000A_- Document that more realistic IP/route semantics come in later scopes._x000A__x000A_### 2. Extend Scheduler to compute route actions per link interval_x000A__x000A_In your Scheduler (e.g. `scheduler.go`), add logic alongside beam scheduling:_x000A__x000A_- For each potential link with visibility intervals `[T_on, T_off]`:_x000A_  - Determine:_x000A_    - `nodeA`, `ifaceA` and `nodeB`, `ifaceB`._x000A_    - Agent IDs for those nodes (you may have a mapping `nodeID → agentID`)._x000A__x000A_Then:_x000A__x000A_- At `T_on`:_x000A_  - Construct two `ScheduledAction`s:_x000A_    - `ScheduledSetRoute` for node A (agent for A) with a `RouteEntry` to B._x000A_    - `ScheduledSetRoute` for node B (agent for B) with a `RouteEntry` to A._x000A_- At `T_off`:_x000A_  - Construct two `ScheduledDeleteRoute` actions mirroring those entries._x000A__x000A_Pseudo-structure:_x000A__x000A_- You might add a helper:_x000A__x000A_      func (s *Scheduler) scheduleRoutesForLink(link NetworkLink, intervals []VisibilityInterval) error_x000A__x000A_which:_x000A__x000A_- Iterates intervals._x000A_- For each interval, calls lower-level helpers:_x000A__x000A_      s.scheduleSetRouteAt(T_on, nodeA, nodeB, ifaceA)_x000A_      s.scheduleSetRouteAt(T_on, nodeB, nodeA, ifaceB)_x000A_      s.scheduleDeleteRouteAt(T_off, nodeA, nodeB)_x000A_      s.scheduleDeleteRouteAt(T_off, nodeB, nodeA)_x000A__x000A_### 3. Build ScheduledAction payloads for SetRoute/DeleteRoute_x000A__x000A_Implement small helpers on Scheduler (or a separate builder) to construct route actions:_x000A__x000A_- For SetRoute:_x000A__x000A_      func (s *Scheduler) newSetRouteAction(_x000A_          when time.Time,_x000A_          nodeID string,_x000A_          destNodeID string,_x000A_          outInterfaceID string,_x000A_      ) *ScheduledAction_x000A__x000A_Internals:_x000A__x000A_- Build a `RouteEntry`:_x000A__x000A_      route := &amp;RouteEntry{_x000A_          DestinationCIDR: s.destCIDRForNode(destNodeID), // helper from Task 1_x000A_          NextHopNodeID:   destNodeID,_x000A_          OutInterfaceID:  outInterfaceID,_x000A_      }_x000A__x000A_- Create a `ScheduledAction`:_x000A__x000A_      &amp;ScheduledAction{_x000A_          EntryID:   s.nextEntryID(), // helper to generate unique IDs_x000A_          When:      when,_x000A_          Type:      ScheduledSetRoute,_x000A_          RequestID: s.nextRequestID(nodeID),_x000A_          SeqNo:     s.nextSeqNo(nodeID),_x000A_          Token:     s.currentTokenForNode(nodeID),_x000A_          Route:     route,_x000A_      }_x000A__x000A_- For DeleteRoute:_x000A__x000A_      func (s *Scheduler) newDeleteRouteAction(_x000A_          when time.Time,_x000A_          nodeID string,_x000A_          destNodeID string,_x000A_      ) *ScheduledAction_x000A__x000A_Internals:_x000A__x000A_- You can either:_x000A_  - Repeat the same `RouteEntry` fields (for completeness), or_x000A_  - Only send the destination in the proto and let the agent look up and delete it._x000A__x000A_For Scope 4, a simple approach is:_x000A__x000A_- Have `ScheduledAction.Route` filled with the same `DestinationCIDR` you used for SetRoute, and ignore `NextHopNodeID`/`OutInterfaceID` on delete._x000A__x000A_### 4. Wire route actions into CDPI and agents_x000A__x000A_Ensure that:_x000A__x000A_- Controller-side:_x000A__x000A_  - `Scheduler` uses `CDPIServer.SendCreateEntry(agentID, action)` to push:_x000A_    - `ScheduledSetRoute` / `ScheduledDeleteRoute` actions to the right agent._x000A_  - If you don’t yet have a clean `nodeID → agentID` mapping helper, introduce one in the controller layer._x000A__x000A_- Agent-side (from earlier chunks):_x000A__x000A_  - `Agent.execute(action *ScheduledAction)` must already have branches:_x000A__x000A_        case ScheduledSetRoute:_x000A_            // call ScenarioState.InstallRoute(nodeID, *action.Route)_x000A_        case ScheduledDeleteRoute:_x000A_            // call ScenarioState.RemoveRoute(nodeID, action.Route.DestinationCIDR)_x000A__x000A_  - If these branches don’t exist yet, add them now (but keep behavior simple)._x000A__x000A_### 5. Optional: small unit tests for route scheduling_x000A__x000A_While **Chunk 10** will have broader test coverage, add at least a minimal test for this behavior now (to avoid regressions):_x000A__x000A_- In `internal/sbi/controller/scheduler_routes_test.go` or similar:_x000A__x000A_  - Use an in-memory `ScenarioState` with:_x000A_    - Two nodes (A, B)._x000A_    - One link with endpoints (A:ifA, B:ifB)._x000A_    - One visibility interval `[T_on, T_off]`._x000A_  - Use a fake `CDPIServer` that records `SendCreateEntry` calls._x000A_  - Run a single scheduling pass (e.g. `Scheduler.RunOnce()` or a specific `ScheduleRoutesForLinks()`)._x000A__x000A_- Assert:_x000A__x000A_  - Exactly **four** route actions are created:_x000A_    - 2 × `ScheduledSetRoute` (one per node at/on T_on)._x000A_    - 2 × `ScheduledDeleteRoute` (one per node at T_off)._x000A_  - Each `SetRoute` action:_x000A_    - Has `Route.NextHopNodeID` set to the peer node._x000A_    - Has `Route.OutInterfaceID` set to the correct interface._x000A_  - Each `DeleteRoute` action:_x000A_    - Targets the same destination CIDR as the corresponding `SetRoute`._x000A__x000A_## Acceptance criteria_x000A__x000A_- Scheduler behavior:_x000A__x000A_  - For each potential link with visibility interval `[T_on, T_off]`:_x000A_    - Scheduler generates **two** `ScheduledSetRoute` actions at/on `T_on` (one per endpoint)._x000A_    - Scheduler generates **two** `ScheduledDeleteRoute` actions at `T_off` (one per endpoint)._x000A_  - Route actions are sent via CDPI to the appropriate agents._x000A__x000A_- Route modeling:_x000A__x000A_  - A consistent `DestinationCIDR` scheme is defined for "node-to-node" routes._x000A_  - `RouteEntry.NextHopNodeID` and `RouteEntry.OutInterfaceID` are filled correctly for single-hop routes._x000A_  - ScenarioState’s `InstallRoute` / `RemoveRoute` helpers are used for all route mutations._x000A__x000A_- Agent integration:_x000A__x000A_  - Agent `execute` logic handles:_x000A_    - `ScheduledSetRoute` by calling `InstallRoute` on ScenarioState._x000A_    - `ScheduledDeleteRoute` by calling `RemoveRoute` with the correct destination key._x000A_  - No panics or inconsistent state when route actions are executed multiple times or out of order (idempotent enough for Scope 4)._x000A__x000A_- Tests (at least minimal):_x000A__x000A_  - A Scheduler-focused test (or tests) verifies:_x000A_    - That for a simple topology with one link and one visibility interval, the expected `ScheduledSetRoute` / `ScheduledDeleteRoute` actions are produced._x000A_    - That actions contain correct `nodeID`, `destination`, and `outInterfaceID` for both endpoints._x000A__x000A_- Repository health:_x000A__x000A_  - `go build ./...` passes after adding route scheduling code._x000A_  - `go test ./...` passes, including the new route scheduling tests._x000A_</S>
      <S N="State2">open</S>
    </MS>
  </Obj>
  <Obj RefId="3">
    <TNRef RefId="0" />
    <MS>
      <S N="Topic">Startup</S>
      <I32 N="Issue1">166</I32>
      <S N="Title1">[Scope 4][Chunk 9] Wire Scenario Startup: Instantiate Scheduler, CDPI Server, Telemetry Server, and Agents</S>
      <S N="Body1">## Background_x000A__x000A_Chunk 9 focuses on integrating the SBI system (Scheduler, Agents, CDPI, Telemetry) into the **normal simulator scenario lifecycle**, so that scheduling/telemetry operates automatically whenever a scenario is loaded and executed._x000A__x000A_Up to Chunk 8, we have:_x000A__x000A_- A `ScenarioState` that holds the network KB (nodes/interfaces/links)._x000A_- A working `EventScheduler` tied to simulation time._x000A_- Implemented:_x000A_  - CDPIServer (controller-side API for agents)._x000A_  - TelemetryServer + TelemetryState._x000A_  - Agent model (per-node)._x000A_  - Basic Scheduler component that generates ScheduledActions._x000A__x000A_But right now, these components are **not yet wired** into the actual simulator startup path — they exist but nothing triggers them when a scenario is loaded._x000A__x000A_Chunk 9 requires integrating everything such that:_x000A__x000A_- When a scenario loads (from NBI or config),_x000A_- Components bootstrap in the correct order,_x000A_- Agents connect to the controller,_x000A_- CDPI and Telemetry gRPC services are live,_x000A_- Scheduler pre-populates its initial schedule,_x000A_- Time loop triggers the scheduler and agents correctly._x000A__x000A_This issue implements **Scenario Startup Wiring**._x000A__x000A_---_x000A__x000A_## Goals_x000A__x000A_1. Integrate **Scheduler**, **CDPIServer**, **TelemetryServer**, and **Agents** into the main simulation initialization flow._x000A_2. Ensure:_x000A_   - CDPIServer and TelemetryServer are registered on the gRPC server._x000A_   - Each node in the scenario spawns its Agent._x000A_   - Scheduler is created and ready to issue actions._x000A_   - Telemetry interval is injected into agents._x000A_3. Ensure simulation loop drives:_x000A_   - Time controller advancement,_x000A_   - EventScheduler execution,_x000A_   - Scheduler runs if needed (on startup or periodically)._x000A_4. Add minimal logging to confirm startup._x000A__x000A_---_x000A__x000A_## Tasks_x000A__x000A_### 1. Modify Scenario Startup Path_x000A__x000A_In `cmd/simulator` or central runner:_x000A__x000A_- After scenario load + time controller init:_x000A_  - Create `EventScheduler` instance._x000A_  - Create `TelemetryState` and `TelemetryServer`._x000A_  - Create `CDPIServer`._x000A_  - Create `Scheduler` with:_x000A_    - ScenarioState_x000A_    - EventScheduler_x000A_    - CDPIServer_x000A__x000A_### 2. Instantiate Agents for Each Node_x000A__x000A_For each `NetworkNode`:_x000A__x000A_- Create `Agent` with:_x000A_  - `NodeID`_x000A_  - `ScenarioState`_x000A_  - `EventScheduler`_x000A_  - Telemetry client stub (from gRPC connection)_x000A_  - CDPI client stub (from gRPC connection)_x000A_  - Configured telemetry interval_x000A__x000A_- Call:_x000A__x000A_```go_x000A_agent.Start(ctx)_x000A_```_x000A__x000A_Start failure should log but not crash scenario._x000A__x000A_### 3. Register gRPC Services_x000A__x000A_In the existing gRPC server:_x000A__x000A_- Register CDPI server:_x000A__x000A_```go_x000A_scheduling.RegisterControlDataPlaneInterfaceServer(grpcServer, cdpiServer)_x000A_```_x000A__x000A_- Register Telemetry server:_x000A__x000A_```go_x000A_telemetry.RegisterTelemetryServiceServer(grpcServer, telemetryServer)_x000A_```_x000A__x000A_### 4. Pre-populate Schedule (Scheduler Warm-Up)_x000A__x000A_After all agents are running:_x000A__x000A_- Invoke:_x000A__x000A_```go_x000A_scheduler.PrecomputeInitialActions()_x000A_```_x000A__x000A_This runs link-driven scheduling and ServiceRequest-aware scheduling **once** to push initial actions to agents._x000A__x000A_### 5. Integrate Into Main Simulation Loop_x000A__x000A_Modify main tick loop:_x000A__x000A_- Advance simulation time_x000A_- Run `EventScheduler.RunDue()`_x000A_- Optionally run scheduler if periodic mode is desired_x000A__x000A_---_x000A__x000A_## Acceptance Criteria_x000A__x000A_- On scenario start:_x000A_  - CDPI server and Telemetry server are running._x000A_  - Each node spawns a connected Agent._x000A_  - Scheduler warms up and sends initial CreateEntryRequests._x000A_  - Agents receive and schedule actions._x000A_- EventScheduler fires scheduled callbacks as time advances._x000A_- Telemetry loop inside each agent begins sending metrics._x000A_- No panics or deadlocks._x000A_- Logs confirm:_x000A_  - Agents connected via Hello_x000A_  - Scheduler sending entries_x000A_  - Telemetry arriving at controller_x000A_- `go build` and `go test` pass._x000A__x000A_---_x000A__x000A_## Output Deliverables_x000A__x000A_- Changes in:_x000A_  - `cmd/simulator/main.go` or scenario runner_x000A_  - Wiring code for agents, scheduler, CDPIServer, TelemetryServer_x000A_  - Logging improvements_x000A_- A fully functional scenario startup sequence where SBI operates automatically._x000A_</S>
      <S N="State1">open</S>
      <I32 N="Issue2">167</I32>
      <S N="Title2">[Scope 4][Chunk 9] Wire SBI components into simulator scenario startup</S>
      <S N="Body2">## Background_x000A__x000A_By this point you have, in earlier Scope 4 chunks:_x000A__x000A_- SBI domain and plumbing:_x000A_  - `EventScheduler` interface + real/fake implementations (Chunk 3)._x000A_  - `Agent` implementation with:_x000A_    - Local schedule queue and execution._x000A_    - CDPI stream handling._x000A_    - Telemetry loop (Chunk 4, 6, 7)._x000A_  - `CDPIServer` implementing `ControlDataPlaneInterface.ReceiveRequests` (Chunk 5)._x000A_  - `TelemetryServer` + `TelemetryState` (Chunk 6)._x000A_  - Controller-side `Scheduler` that:_x000A_    - Inspects `ScenarioState`._x000A_    - Emits `ScheduledAction`s via CDPI (Chunk 8)._x000A__x000A_- NBI-based scenario load path:_x000A_  - A way to load/create `ScenarioState` from NBI / config._x000A_  - A time controller / sim clock driving Scope 1/2 dynamics._x000A__x000A_What’s missing in **Chunk 9** is wiring all of these SBI components into the **simulator startup** so that:_x000A__x000A_- When you start a scenario:_x000A_  - SBI servers (CDPI + Telemetry) are created and registered on the gRPC server._x000A_  - A controller `Scheduler` is instantiated and pointed at `ScenarioState` + `CDPIServer`._x000A_  - One `Agent` per node is created and started, connected back to CDPI as a client._x000A_- When the scenario ends or context is cancelled:_x000A_  - Agents are stopped cleanly._x000A_  - SBI servers can shut down along with the main gRPC server._x000A__x000A_This issue focuses on the **startup wiring** and lifecycle plumbing in the simulator process, without yet adding feature flags or advanced run-loop integration (those come in related Chunk 9 issues)._x000A__x000A_## Goal_x000A__x000A_- Extend the simulator’s **scenario startup flow** to:_x000A_  - Construct and own all SBI components:_x000A_    - `EventScheduler` (real implementation)._x000A_    - `TelemetryState` + `TelemetryServer`._x000A_    - `CDPIServer`._x000A_    - Controller `Scheduler`._x000A_    - Per-node `Agent` instances._x000A_  - Register CDPI and Telemetry services on the gRPC server._x000A_  - Start agents so they connect to CDPI and begin participating in SBI._x000A_- Ensure there is a clear ownership / lifecycle:_x000A_  - Where they are created._x000A_  - How they are wired together._x000A_  - How they are shut down on scenario stop or context cancel._x000A_- Keep the wiring **minimal but explicit**, making future refactors (flags, multiple scenarios, etc.) straightforward._x000A__x000A_## Where to look_x000A__x000A_Simulator entrypoints / scenario orchestration:_x000A__x000A_- CLI / main:_x000A_  - `cmd/simulator/main.go` or equivalent._x000A_- Scenario runner:_x000A_  - Something like `sim/runner`, `internal/sim/runner.go` or `internal/app/simulator.go`._x000A_  - Wherever you currently:_x000A_    - Load a scenario via NBI or config._x000A_    - Build `ScenarioState`._x000A_    - Create the time controller._x000A_    - Start the sim run loop._x000A__x000A_Existing state and SBI components:_x000A__x000A_- `ScenarioState`:_x000A_  - Under `internal/sim/state` or `sim/state`._x000A_  - Where links, nodes, and interfaces are already managed._x000A__x000A_- SBI domain:_x000A_  - `internal/sbi/agent`:_x000A_    - `Agent` struct and constructor(s)._x000A_  - `internal/sbi/controller`:_x000A_    - `CDPIServer`._x000A_    - `Scheduler`._x000A__x000A_- Telemetry:_x000A_  - `TelemetryState` and `TelemetryServer`:_x000A_    - Likely under `internal/sbi/telemetry` or `sim/state/telemetry`._x000A__x000A_gRPC server wiring:_x000A__x000A_- Wherever NBI services are registered:_x000A_  - The existing call site for:_x000A_    - `nbi.RegisterScenarioServiceServer(grpcServer, ...)`_x000A_    - Other NBI services._x000A_- This is where you’ll also register:_x000A_  - `scheduling.RegisterControlDataPlaneInterfaceServer(grpcServer, cdpiServer)`_x000A_  - `telemetry.RegisterTelemetryServiceServer(grpcServer, telemetryServer)`_x000A__x000A_Search terms:_x000A__x000A_- `ScenarioState`_x000A_- `NewScenarioState` / `BuildScenarioState`_x000A_- `grpc.NewServer`_x000A_- `RegisterScenarioServiceServer`_x000A_- `Agent` (under `internal/sbi/agent`)_x000A_- `CDPIServer`_x000A_- `Scheduler` (controller)_x000A__x000A_## Tasks_x000A__x000A_### 1. Introduce a SBI wiring helper / struct_x000A__x000A_Create a small package or helper that encapsulates SBI wiring, e.g.:_x000A__x000A_- `internal/sbi/runtime` or similar:_x000A__x000A_      type SBIRuntime struct {_x000A_          State      *simstate.ScenarioState_x000A_          Clock      sbi.EventScheduler_x000A_          Telemetry  *TelemetryState_x000A_          TelemetryS *TelemetryServer_x000A_          CDPI       *CDPIServer_x000A_          Scheduler  *Scheduler_x000A_          Agents     []*agent.Agent_x000A__x000A_          // Optional:_x000A_          // shutdown hooks, waitgroups, logger, etc._x000A_      }_x000A__x000A_Add a constructor:_x000A__x000A_- `func NewSBIRuntime(state *simstate.ScenarioState, clock sbi.EventScheduler, conn *grpc.ClientConn, logger Logger) (*SBIRuntime, error)`_x000A__x000A_  - Parameters:_x000A_    - `state`: the already-built `ScenarioState`._x000A_    - `clock`: real `EventScheduler` implementation bound to sim clock._x000A_    - `conn`: gRPC client connection that agents will use to reach CDPI/Telemetry (if in-process, you may have a special client factory; wire whatever you already use for NBI)._x000A_    - `logger`: optional structured logger._x000A__x000A_- Responsibilities inside `NewSBIRuntime`:_x000A_  - Create `TelemetryState` and `TelemetryServer`._x000A_  - Create `CDPIServer` with:_x000A_    - `State` and `Clock`._x000A_  - Create controller `Scheduler` with:_x000A_    - `State`, `Clock`, `CDPI`._x000A_  - Iterate over nodes in `ScenarioState` and:_x000A_    - For each node that should have an agent, create an `Agent` configured with:_x000A_      - `NodeID` and `AgentID`._x000A_      - Shared `ScenarioState`._x000A_      - Shared `EventScheduler`._x000A_      - Telemetry client stub._x000A_      - CDPI client stub (for the agent’s `ReceiveRequests` stream)._x000A_      - Logger._x000A_    - Append each agent to `Agents`._x000A__x000A_&gt; Design note: If your agents call CDPI over the same in-process gRPC server, you might have to:_x000A_&gt; - Start the server first._x000A_&gt; - Dial a loopback client connection for agents (`grpc.DialContext("localhost:port", ...)`)._x000A_&gt; This issue can treat that detail as “already available”, or document that it’s done at the caller site._x000A__x000A_### 2. Register SBI servers with the gRPC server_x000A__x000A_In the main simulator wiring (where you create your gRPC server):_x000A__x000A_- After `grpc.NewServer()` and before `Serve`:_x000A__x000A_  - Create or receive the `SBIRuntime`._x000A_  - Register SBI servers:_x000A__x000A_        scheduling.RegisterControlDataPlaneInterfaceServer(grpcServer, sbiRuntime.CDPI)_x000A_        telemetry.RegisterTelemetryServiceServer(grpcServer, sbiRuntime.TelemetryS)_x000A__x000A_  - Keep the existing NBI server registrations unchanged._x000A__x000A_- Ensure `SBIRuntime` is reachable from the main run loop:_x000A_  - Store it in a higher-level struct, e.g.:_x000A__x000A_        type App struct {_x000A_            GRPC      *grpc.Server_x000A_            State     *simstate.ScenarioState_x000A_            Clock     sbi.EventScheduler_x000A_            SBIRuntime *sbi_runtime.SBIRuntime_x000A_            // ..._x000A_        }_x000A__x000A_### 3. Start agents as part of scenario startup_x000A__x000A_In the scenario startup sequence (after building `ScenarioState`, `Clock`, and `SBIRuntime`):_x000A__x000A_- Start agents:_x000A__x000A_      func (r *SBIRuntime) StartAgents(ctx context.Context) error {_x000A_          var wg sync.WaitGroup_x000A_          var firstErr error_x000A_          for _, ag := range r.Agents {_x000A_              wg.Add(1)_x000A_              go func(a *agent.Agent) {_x000A_                  defer wg.Done()_x000A_                  if err := a.Start(ctx); err != nil {_x000A_                      // record/log error; for now, capture the first one_x000A_                  }_x000A_              }(ag)_x000A_          }_x000A_          // Optionally return early if you want async behavior,_x000A_          // or wait for a first successful Hello/stream in each Agent.Start._x000A_          return firstErr_x000A_      }_x000A__x000A_- Call this from the main scenario runner:_x000A__x000A_      // 1) Load scenario &amp; build ScenarioState._x000A_      // 2) Create EventScheduler bound to sim time controller._x000A_      // 3) Create SBIRuntime (CDPI, Telemetry, Scheduler, Agents)._x000A_      // 4) Register SBI services on the grpc.Server._x000A_      // 5) Start grpc.Server (if not already running)._x000A_      // 6) Start agents with the scenario context._x000A__x000A_- Ensure that:_x000A_  - Agents use a context tied to the scenario lifecycle (cancelled when scenario ends)._x000A_  - Any errors in agent startup are logged and surfaced appropriately._x000A__x000A_### 4. Ensure clean shutdown of agents &amp; SBI components_x000A__x000A_Add shutdown/cleanup methods on `SBIRuntime`, e.g.:_x000A__x000A_- `func (r *SBIRuntime) StopAgents()`_x000A_- `func (r *SBIRuntime) Close()`_x000A__x000A_Implementation sketches:_x000A__x000A_- `StopAgents`:_x000A_  - If agents hold onto a context cancel function, call it._x000A_  - Or expose `Agent.Stop()` and call it for each agent._x000A_- `Close`:_x000A_  - Stop agents._x000A_  - Optionally flush any outstanding scheduler state._x000A_  - Let the main app handle `grpcServer.GracefulStop()`._x000A__x000A_Wire `SBIRuntime.Close()` into your simulator shutdown path:_x000A__x000A_- On scenario completion or process termination:_x000A_  - Cancel the main context._x000A_  - Call `SBIRuntime.Close()`._x000A_  - Stop the gRPC server._x000A__x000A_### 5. Minimal integration tests (optional but recommended for this issue)_x000A__x000A_If feasible within this issue (or as a follow-up test issue):_x000A__x000A_- Add a basic integration test under `internal/sim` or `internal/sbi`:_x000A__x000A_  - Construct:_x000A_    - In-memory `ScenarioState` with a couple of nodes._x000A_    - Fake `EventScheduler`._x000A_    - In-process gRPC server._x000A_  - Wire up `SBIRuntime`._x000A_  - Start:_x000A_    - gRPC server._x000A_    - Agents._x000A_  - Assert that:_x000A_    - Agents connect to CDPI (Hello logged/observed)._x000A_    - Telemetry / CDPI servers are registered and can be dialed._x000A__x000A_&gt; If this is too heavy for the current issue, at least add TODOs / comments indicating where dedicated integration tests will live (likely under Chunk 11 “in-process gRPC SBI &amp; Telemetry tests”)._x000A__x000A_## Acceptance criteria_x000A__x000A_- SBI runtime wiring:_x000A_  - There is a clear `SBIRuntime` (or similar) construct that:_x000A_    - Owns `TelemetryState` + `TelemetryServer`._x000A_    - Owns `CDPIServer`._x000A_    - Owns controller `Scheduler`._x000A_    - Owns a list of `Agent` instances._x000A_  - `SBIRuntime` is created during scenario startup with references to:_x000A_    - `ScenarioState`._x000A_    - Real `EventScheduler`._x000A_    - gRPC client connection(s) needed for agents._x000A__x000A_- gRPC server registration:_x000A_  - `ControlDataPlaneInterface` server (`CDPIServer`) is registered on the simulator’s gRPC server._x000A_  - `TelemetryService` server (`TelemetryServer`) is registered on the simulator’s gRPC server._x000A_  - Existing NBI server registration continues to work._x000A__x000A_- Agent lifecycle:_x000A_  - On scenario startup:_x000A_    - One `Agent` per relevant node is created and started._x000A_    - Agents use the shared `EventScheduler` and `ScenarioState`._x000A_    - Agents are able to connect to the in-process CDPI server via client stubs._x000A_  - On scenario shutdown:_x000A_    - Agents are stopped cleanly (via context cancel or explicit `Stop()`)._x000A_    - No goroutines are left hanging in steady-state tests._x000A__x000A_- Separation of concerns:_x000A_  - Simulator entrypoint / runner is responsible for:_x000A_    - Building `ScenarioState` and time controller._x000A_    - Creating and owning `SBIRuntime`._x000A_    - Registering services and starting the gRPC server._x000A_  - `SBIRuntime` is responsible for:_x000A_    - Constructing SBI components._x000A_    - Starting and stopping agents._x000A__x000A_- Repository health:_x000A_  - `go build ./...` passes after wiring changes._x000A_  - Existing unit tests continue to pass._x000A_  - Any new tests added for SBI wiring also pass._x000A_</S>
      <S N="State2">open</S>
    </MS>
  </Obj>
  <Obj RefId="4">
    <TNRef RefId="0" />
    <MS>
      <S N="Topic">Run Loop</S>
      <I32 N="Issue1">168</I32>
      <S N="Title1">[Scope 4][Chunk 9] Implement simulation run loop &amp; EventScheduler integration</S>
      <S N="Body1">## Background_x000A__x000A_By this point in **Scope 4** you have:_x000A__x000A_- A working **ScenarioState**:_x000A_  - Holds nodes, interfaces, links, service requests, etc._x000A_- A **real EventScheduler** implementation (Chunk 3):_x000A_  - Backed by the simulation clock / time controller._x000A_  - Supports `Schedule`, `Cancel`, and `Now`._x000A_- A set of **Agents** (Chunk 4):_x000A_  - Own local scheduled actions._x000A_  - Use `EventScheduler` to execute actions at the right sim time._x000A_  - Emit telemetry via TelemetryService._x000A_- A **Scheduler** on the controller side (Chunk 8):_x000A_  - Generates `ScheduledAction`s for beams and routes._x000A_  - Sends them to agents via CDPI._x000A_- SBI plumbing (Chunks 5–7):_x000A_  - CDPI server and agent streams._x000A_  - Telemetry service._x000A_  - Reset / Finalize / tokens semantics._x000A__x000A_What’s still missing for **Chunk 9** is a *single, coherent run loop* that:_x000A__x000A_- Drives the **simulation clock** forward._x000A_- Ensures the **EventScheduler** runs due events at each step._x000A_- Coordinates:_x000A_  - **Scenario startup** (loading a scenario and wiring SBI)._x000A_  - **Scheduler execution** (when and how often to compute schedules)._x000A_  - **Agent lifecycle** (start/stop tied to scenario lifecycle)._x000A__x000A_Right now, you might have separate pieces that “can” be wired together, but no concrete, documented **run loop** that a developer can call (e.g. `RunScenario(ctx, cfg)`)._x000A__x000A_This issue focuses on the **core run loop integration**:_x000A_- How sim time advances._x000A_- When EventScheduler events are executed._x000A_- Where controller Scheduler and agents are invoked._x000A__x000A_Configuration flags (`--enable-sbi`, `--telemetry-interval`, etc.) are handled in a separate Chunk 9 issue._x000A__x000A_## Goal_x000A__x000A_Provide a clear, testable **simulation run loop** that:_x000A__x000A_- Drives the **sim clock** and **EventScheduler** together._x000A_- Starts and stops:_x000A_  - CDPI server._x000A_  - Telemetry server._x000A_  - Controller Scheduler._x000A_  - Agents (one per node)._x000A_- Provides a single entry point (or small API) to:_x000A_  - Load a scenario._x000A_  - Wire SBI components._x000A_  - Run the simulation until:_x000A_    - A specified sim-time horizon, or_x000A_    - Context cancellation / shutdown._x000A__x000A_## Where to look_x000A__x000A_Scenario lifecycle &amp; main entry:_x000A__x000A_- Existing CLI / main entry points, e.g.:_x000A_  - `cmd/simulator/main.go`_x000A_  - Or a `sim/runner` package._x000A_- Where scenarios are currently:_x000A_  - Loaded (via NBI or static config)._x000A_  - Bound to `ScenarioState`._x000A_  - Driven by a time controller / timectrl package._x000A__x000A_Time controller &amp; scheduler:_x000A__x000A_- Time control module, e.g. `timectrl`:_x000A_  - Provides:_x000A_    - `Now()` equiv._x000A_    - `StepTo(t time.Time)` or a loop over time steps._x000A_- Event scheduler implementation (Chunk 3), e.g.:_x000A_  - `internal/sbi/eventscheduler.go`_x000A_  - Functions:_x000A_    - `Schedule(at time.Time, f func()) (id string)`_x000A_    - `Cancel(id string)`_x000A_    - `Now() time.Time`_x000A_    - Possibly `RunDue(now time.Time)` or similar._x000A__x000A_SBI components:_x000A__x000A_- CDPI server (Chunk 5), e.g. `internal/sbi/controller/cdpi_server.go`._x000A_- Telemetry server (Chunk 6), e.g. `internal/sbi/telemetry_server.go`._x000A_- Controller Scheduler (Chunk 8), e.g. `internal/sbi/controller/scheduler.go`._x000A_- Agent code (Chunk 4), e.g. `internal/sbi/agent/agent.go`._x000A__x000A_Search terms:_x000A__x000A_- `ScenarioState`_x000A_- `RunScenario`_x000A_- `EventScheduler`_x000A_- `timectrl`_x000A_- `CDPIServer`_x000A_- `TelemetryServer`_x000A_- `Scheduler struct`_x000A_- `Agent struct`_x000A__x000A_## Tasks_x000A__x000A_### 1. Define a central RunScenario API_x000A__x000A_Create a new package or file (if not already present), for example:_x000A__x000A_- `internal/simrunner/runner.go` or_x000A_- `sim/runner.go`_x000A__x000A_Define a struct to hold run-time wiring:_x000A__x000A_- Example:_x000A__x000A_      type ScenarioRunner struct {_x000A_          State     *simstate.ScenarioState_x000A_          Clock     timectrl.SimClock        // or equivalent interface_x000A_          Scheduler sbi.EventScheduler       // real EventScheduler_x000A__x000A_          CDPI      *sbi.CDPIServer_x000A_          Telemetry *sbi.TelemetryServer_x000A_          CtrlSched *sbi.Scheduler           // controller scheduling logic_x000A__x000A_          Agents    []*sbi.Agent_x000A_      }_x000A__x000A_Add a constructor or helper:_x000A__x000A_- Example:_x000A__x000A_      type RunnerConfig struct {_x000A_          Scenario     *simstate.ScenarioState_x000A_          Clock        timectrl.SimClock_x000A_          Scheduler    sbi.EventScheduler_x000A_          CDPIServer   *sbi.CDPIServer_x000A_          TelemetrySrv *sbi.TelemetryServer_x000A_          Controller   *sbi.Scheduler_x000A_          Agents       []*sbi.Agent_x000A__x000A_          EndTime      time.Time // sim-time horizon_x000A_      }_x000A__x000A_      func NewScenarioRunner(cfg RunnerConfig) *ScenarioRunner_x000A__x000A_Design notes:_x000A__x000A_- `RunnerConfig` should be easy to build from `cmd/simulator`._x000A_- `EndTime` can be:_x000A_  - A fixed horizon, or_x000A_  - Zero-value to mean “run until context cancel”._x000A__x000A_### 2. Implement ScenarioRunner.Start / Stop_x000A__x000A_Add top-level methods:_x000A__x000A_- `Start(ctx context.Context) error`_x000A_- `Run(ctx context.Context) error` (or combine Start+Run)_x000A_- `Stop()` / `Shutdown()` to cleanly stop agents and servers._x000A__x000A_Suggested flow in `Start`:_x000A__x000A_1. Start Telemetry and CDPI gRPC servers (or assume they are already bound to a shared server; at minimum ensure they’re configured)._x000A_2. Start each **Agent**:_x000A_   - `for _, a := range r.Agents { go a.Start(ctx) }`_x000A_3. Start the **controller Scheduler**, if it has a loop:_x000A_   - Either:_x000A_     - Provide a `CtrlSched.Start(ctx)` that runs in a goroutine, or_x000A_     - Call a one-shot `CtrlSched.PrimeSchedule()` if you pre-compute schedules._x000A_4. Ensure **Clock** and **Scheduler** share the same notion of `Now()`._x000A__x000A_`Stop` should:_x000A__x000A_- Cancel the context or call `Agent.Stop()` on each agent._x000A_- Stop any controller Scheduler loop if it has one._x000A_- Stop gRPC servers if they are owned here._x000A__x000A_### 3. Implement the main run loop (sim time + EventScheduler)_x000A__x000A_Add a method like:_x000A__x000A_- `func (r *ScenarioRunner) RunUntil(ctx context.Context, endTime time.Time) error`_x000A__x000A_Core logic:_x000A__x000A_1. Determine initial time:_x000A__x000A_       now := r.Clock.Now()_x000A__x000A_2. Loop until end condition:_x000A__x000A_       for {_x000A_           // Check context cancellation first._x000A_           select {_x000A_           case &lt;-ctx.Done():_x000A_               return ctx.Err()_x000A_           default:_x000A_           }_x000A__x000A_           now = r.Clock.Now()_x000A_           if !endTime.IsZero() &amp;&amp; !now.Before(endTime) {_x000A_               break_x000A_           }_x000A__x000A_           // 1) Run due EventScheduler events at this time._x000A_           r.Scheduler.RunDue(now) // or equivalent_x000A__x000A_           // 2) Advance sim time:_x000A_           //    - Either a fixed step, or_x000A_           //    - To next scheduled event / connectivity event._x000A_           next := r.nextSimStep(now, endTime)_x000A_           if next.IsZero() || !next.After(now) {_x000A_               // Avoid infinite loop; choose a minimal step._x000A_               next = now.Add(time.Second)_x000A_           }_x000A__x000A_           // Advance time controller to `next`._x000A_           if err := r.Clock.StepTo(next); err != nil {_x000A_               return err_x000A_           }_x000A_       }_x000A__x000A_3. After loop, optionally do a final `RunDue(endTime)` to flush events._x000A__x000A_`nextSimStep` can be a helper:_x000A__x000A_- For now, keep it simple:_x000A__x000A_      func (r *ScenarioRunner) nextSimStep(now, endTime time.Time) time.Time {_x000A_          // For Scope 4, a fixed delta (e.g. 1s or 10s) is fine._x000A_          step := 1 * time.Second_x000A_          candidate := now.Add(step)_x000A_          if !endTime.IsZero() &amp;&amp; candidate.After(endTime) {_x000A_              return endTime_x000A_          }_x000A_          return candidate_x000A_      }_x000A__x000A_Design notes:_x000A__x000A_- Future scopes might replace this with:_x000A_  - “Jump to next event time” strategy._x000A_  - Integration with connectivity “in view” events._x000A__x000A_### 4. Ensure controller Scheduler hooks into the run loop_x000A__x000A_If your controller Scheduler has its own periodic loop:_x000A__x000A_- For example, a method:_x000A__x000A_      func (s *Scheduler) Tick(now time.Time)_x000A__x000A_Then integrate it into the run loop:_x000A__x000A_- Inside each loop iteration (or every N iterations):_x000A__x000A_      r.CtrlSched.Tick(now)_x000A__x000A_If your Scheduler is event-driven or precomputes actions:_x000A__x000A_- You might have:_x000A__x000A_      func (s *Scheduler) PopulateInitialSchedule(horizon time.Time) error_x000A__x000A_Call this once before the main loop:_x000A__x000A_- In `Start` or before `RunUntil` begins._x000A__x000A_Design notes:_x000A__x000A_- For Scope 4, you can keep the Scheduler **simple**:_x000A_  - Precompute a schedule up to `endTime`._x000A_  - Or run a `Tick` each loop to:_x000A_    - Look at connectivity and service requests._x000A_    - Issue new CreateEntryRequests via CDPI as needed._x000A__x000A_### 5. Integrate with existing main / CLI_x000A__x000A_Wire `ScenarioRunner` into your existing entry point, e.g. `cmd/simulator/main.go`:_x000A__x000A_1. Parse CLI flags (Scope 9 config handled in a separate issue)._x000A_2. Build ScenarioState (load scenario via NBI or static config)._x000A_3. Construct:_x000A_   - SimClock / time controller._x000A_   - EventScheduler instance bound to sim clock._x000A_   - TelemetryState + TelemetryServer._x000A_   - CDPIServer._x000A_   - Controller Scheduler._x000A_   - Agents:_x000A_     - One `Agent` per NetworkNode that should participate in SBI._x000A_4. Build `RunnerConfig` and `ScenarioRunner`._x000A_5. Call:_x000A__x000A_       ctx, cancel := context.WithCancel(context.Background())_x000A_       defer cancel()_x000A__x000A_       if err := runner.Start(ctx); err != nil {_x000A_           // log and exit_x000A_       }_x000A__x000A_       endTime := scenarioEndTimeFromConfigOrState(...)_x000A_       if err := runner.RunUntil(ctx, endTime); err != nil {_x000A_           // log and exit_x000A_       }_x000A__x000A_       runner.Stop()_x000A__x000A_Make sure this path is:_x000A__x000A_- The **default** when Scope 4 is enabled._x000A_- Trivially bypassed if someone runs a minimal core-only mode (Scope 1–3 only)._x000A__x000A_### 6. Add unit tests for the run loop_x000A__x000A_Create a test file, e.g.:_x000A__x000A_- `internal/simrunner/runner_test.go`_x000A__x000A_Use fakes:_x000A__x000A_- **FakeSimClock**:_x000A_  - Stores current time._x000A_  - Implements `Now()` and `StepTo(t time.Time)`._x000A_- **FakeEventScheduler**:_x000A_  - Records events._x000A_  - Provides `RunDue(now time.Time)` that:_x000A_    - Runs any events scheduled at or before `now`._x000A_- **FakeScheduler (controller)**:_x000A_  - Records calls to `Tick(now)` or `PopulateInitialSchedule`._x000A_- **FakeAgent**:_x000A_  - Minimal struct implementing:_x000A_    - `Start(ctx)` → record “started”._x000A_    - `Stop()` → record “stopped”._x000A__x000A_Test cases:_x000A__x000A_1. Run loop advances sim time and runs scheduler events_x000A__x000A_   - Given:_x000A_     - Start time `T0`._x000A_     - End time `T0 + 3s`._x000A_     - A fake EventScheduler that:_x000A_       - Has one event scheduled at `T0 + 2s`._x000A_   - When:_x000A_     - `RunUntil(ctx, endTime)` is called._x000A_   - Assert:_x000A_     - Sim clock `Now()` ends at or after `endTime`._x000A_     - Scheduled event was executed exactly once._x000A_     - Controller Scheduler’s `Tick` (if used) was called at least once._x000A__x000A_2. Agents are started and stopped_x000A__x000A_   - Given:_x000A_     - Runner with two fake agents._x000A_   - When:_x000A_     - `Start(ctx)` then `RunUntil(ctx, endTime)` then `Stop()`._x000A_   - Assert:_x000A_     - Each fake agent recorded `Start` and `Stop` calls._x000A_     - No panics or deadlocks._x000A__x000A_3. RunUntil respects context cancellation_x000A__x000A_   - Given:_x000A_     - A context that is cancelled mid-run._x000A_   - When:_x000A_     - `RunUntil(ctx, endTime)` is running._x000A_   - Then:_x000A_     - It exits with `context.Canceled` (or similar)._x000A_     - No further EventScheduler `RunDue` calls occur after cancel._x000A__x000A_4. EndTime = zero means “run until cancel”_x000A__x000A_   - Given:_x000A_     - `endTime` is zero-value._x000A_   - When:_x000A_     - You run `RunUntil(ctx, time.Time{})` and cancel context after some iterations._x000A_   - Assert:_x000A_     - Run loop exits only when context is cancelled._x000A__x000A_## Acceptance criteria_x000A__x000A_- **ScenarioRunner API**:_x000A_  - A `ScenarioRunner` (or equivalent) type exists with:_x000A_    - Fields tying together:_x000A_      - `ScenarioState`_x000A_      - `SimClock`_x000A_      - `EventScheduler`_x000A_      - `CDPIServer`_x000A_      - `TelemetryServer`_x000A_      - Controller `Scheduler`_x000A_      - Agents slice_x000A_    - A constructor or helper to build it from a `RunnerConfig`._x000A__x000A_- **Lifecycle methods**:_x000A_  - `Start(ctx)`:_x000A_    - Starts agents._x000A_    - Wires controller Scheduler (precompute or loop)._x000A_    - Ensures SBI services are ready._x000A_  - `RunUntil(ctx, endTime)`:_x000A_    - Advances simulation time via the sim clock._x000A_    - Calls `EventScheduler.RunDue` (or equivalent) at each step._x000A_    - Integrates controller Scheduler (`Tick` or precomputed schedule)._x000A_    - Respects context cancellation and `endTime`._x000A_  - `Stop()`:_x000A_    - Stops agents and any controller Scheduler loop._x000A_    - Cleanly shuts down any owned servers (if applicable)._x000A__x000A_- **Integration with main / CLI**:_x000A_  - `cmd/simulator` (or equivalent) uses `ScenarioRunner` when Scope 4 is enabled._x000A_  - A developer can:_x000A_    - Load a scenario._x000A_    - Run the sim to a specified sim-time horizon._x000A_    - Observe agents, scheduler, and telemetry all active._x000A__x000A_- **Unit tests**:_x000A_  - Cover:_x000A_    - Sim time advancement and EventScheduler integration._x000A_    - Agents starting and stopping via runner lifecycle._x000A_    - Respecting context cancellation._x000A_    - Behavior when `endTime` is zero vs non-zero._x000A_  - All tests pass via `go test ./...`._x000A__x000A_- **Repository health**:_x000A_  - `go build ./...` passes with the new runner code._x000A_  - No cycles introduced between packages (e.g. `simrunner` vs `sbi` vs `simstate`)._x000A_</S>
      <S N="State1">open</S>
      <I32 N="Issue2">169</I32>
      <S N="Title2">[Scope 4][Chunk 9] Integrate EventScheduler &amp; SBI into main simulation run loop</S>
      <S N="Body2">## Background_x000A__x000A_By Chunk 9, most of the **SBI pieces already exist**:_x000A__x000A_- Core simulation:_x000A_  - `ScenarioState` holds nodes, links, routes, and telemetry-related state._x000A_  - A time controller (e.g. `timectrl`) already advances **simulation time**._x000A_- SBI components:_x000A_  - `EventScheduler` interface + a concrete implementation driven by sim time._x000A_  - Per-node `Agent` instances:_x000A_    - Own local schedules via `EventScheduler`._x000A_    - Execute scheduled actions (beams/routes) against `ScenarioState`._x000A_    - Emit telemetry via `TelemetryService.ExportMetrics`._x000A_  - Controller-side:_x000A_    - `CDPIServer` for CDPI streams (Hello, Reset, Create/Delete/Finalize, Responses)._x000A_    - `TelemetryServer` + `TelemetryState`._x000A_    - `Scheduler` that issues `ScheduledAction`s → `CDPIServer.SendCreateEntry`._x000A__x000A_What’s still missing is the **wiring between the main sim “run loop” and the SBI event scheduler**:_x000A__x000A_- When sim time advances (via existing time controller), **SBI events must be executed**:_x000A_  - Agent actions scheduled via `EventScheduler.Schedule`._x000A_  - Controller-side scheduler actions (if it depends on the same clock)._x000A_- Right now, it’s easy to end up with:_x000A_  - Time advancing but SBI events not triggered._x000A_  - Or SBI scheduler running on wall-clock instead of sim time._x000A_- Chunk 9.2 calls for integrating the `EventScheduler` with the **main simulation run loop**, so that:_x000A_  - Every sim step:_x000A_    - Advances time._x000A_    - Runs due SBI events (agents + controller)._x000A_  - This works both for:_x000A_    - Batch/“planning mode” simulations._x000A_    - Unit/integration tests that drive the sim programmatically._x000A__x000A_This issue connects the dots so SBI becomes a **first-class part of the sim run loop**, not a sidecar._x000A__x000A_## Goal_x000A__x000A_- Ensure the **main simulation loop** (e.g. in `cmd/simulator` or `sim/runner`) drives:_x000A_  - The existing sim time controller._x000A_  - The SBI `EventScheduler`:_x000A_    - Running all events whose `When &lt;= Now()` at each step._x000A_- Make it **clear and testable** how SBI events are processed:_x000A_  - Single well-defined place where `EventScheduler` is pumped._x000A_  - No implicit background goroutines doing “secret” scheduling._x000A_- Keep wiring **simple and deterministic**:_x000A_  - Sim time is the single source of truth._x000A_  - SBI never depends directly on wall-clock time._x000A__x000A_## Where to look_x000A__x000A_Main sim orchestration:_x000A__x000A_- The entry point that:_x000A_  - Loads scenarios via NBI/config._x000A_  - Constructs `ScenarioState`._x000A_  - Owns the time controller and/or “run until” loop._x000A_- Likely files:_x000A_  - `cmd/simulator/main.go`_x000A_  - Or a helper in `sim/runner` / `internal/sim` that:_x000A_    - Has a `RunScenario(ctx, ...)` function._x000A__x000A_Time controller / sim clock:_x000A__x000A_- Existing sim time controller, e.g. `timectrl`:_x000A_  - Provides a `Now()` equivalent and a way to advance the simulation:_x000A_    - Either fixed steps (Δt) or via “next event” logic._x000A_- Search for:_x000A_  - `timectrl`_x000A_  - `Advance`, `Step`, or `Run`_x000A__x000A_EventScheduler implementation:_x000A__x000A_- Your real `EventScheduler` implementation that uses sim time:_x000A_  - Likely in `internal/sbi` or `internal/sbi/scheduler`:_x000A_    - Holds a min-heap / sorted slice of events._x000A_    - Has methods:_x000A__x000A_          type EventScheduler interface {_x000A_              Schedule(at time.Time, f func()) (id string)_x000A_              Cancel(id string)_x000A_              Now() time.Time_x000A_              // For real impl, you may have an internal RunDue() or similar_x000A_          }_x000A__x000A_- There might already be a `RunDue()` helper that executes all callbacks with `When &lt;= Now()`._x000A__x000A_SBI components that rely on EventScheduler:_x000A__x000A_- Agents in `internal/sbi/agent`:_x000A_  - Use `EventScheduler` for:_x000A_    - Executing scheduled CDPI actions._x000A_    - Telemetry ticks (`startTelemetryLoop` / `telemetryTick`)._x000A_- Controller `Scheduler` in `internal/sbi/controller`:_x000A_  - May also depend on `EventScheduler` for:_x000A_    - Periodic recomputation._x000A_    - Or one-shot scheduling at scenario start (Chunk 8)._x000A__x000A_Search terms:_x000A__x000A_- `EventScheduler`_x000A_- `Now() time.Time`_x000A_- `RunScenario`, `Run`, or main simulation loop_x000A_- `timectrl`_x000A__x000A_## Tasks_x000A__x000A_### 1. Identify / define the central sim run-loop_x000A__x000A_- Locate the main simulation loop:_x000A_  - The function that:_x000A_    - Initializes time controller + scenario._x000A_    - Repeatedly advances time until:_x000A_      - End of scenario._x000A_      - Or an external stop condition._x000A_- If it does not exist as a clearly named function, introduce a helper like:_x000A__x000A_      func RunScenario(ctx context.Context, cfg *Config, state *simstate.ScenarioState, clock timectrl.Clock, sbiSched sbi.EventScheduler) error_x000A__x000A_- Design note:_x000A_  - The run-loop should be the **single place** that:_x000A_    - Advances sim time._x000A_    - Triggers SBI events for the current time._x000A__x000A_### 2. Add a clear “pump” for EventScheduler_x000A__x000A_- In the run-loop, after each sim time advance:_x000A_  - Call into the `EventScheduler` to execute due events._x000A_- If your `EventScheduler` already exposes a `RunDue()` (or similar), call it:_x000A__x000A_      for clock.Now().Before(endTime) {_x000A_          // 1. Advance sim time (orbital dynamics, connectivity, etc.)._x000A_          if err := timeCtrl.Step(); err != nil {_x000A_              return err_x000A_          }_x000A__x000A_          // 2. Update internal state dependent on time, if needed (e.g. Scope 2 connectivity)._x000A_          //    This may already be part of timeCtrl.Step()._x000A__x000A_          // 3. Run all SBI events scheduled up to current sim time._x000A_          sbiSched.RunDue()_x000A__x000A_          // 4. Optional: break on ctx.Done(), scenario completion, etc._x000A_      }_x000A__x000A_- If `RunDue()` doesn’t exist yet:_x000A_  - Extend `EventScheduler` interface and implementation:_x000A__x000A_      type EventScheduler interface {_x000A_          Schedule(at time.Time, f func()) (id string)_x000A_          Cancel(id string)_x000A_          Now() time.Time_x000A_          RunDue()_x000A_      }_x000A__x000A_  - Implement `RunDue()` to:_x000A_    - While the earliest event `When &lt;= Now()`:_x000A_      - Pop event._x000A_      - Execute its callback `f()`._x000A__x000A_### 3. Ensure Scheduler &amp; Agents use the same EventScheduler instance_x000A__x000A_- Double-check wiring at scenario startup (Chunk 9.1):_x000A_  - The **same `EventScheduler` instance** should be passed to:_x000A_    - The controller `Scheduler`._x000A_    - Each `Agent`._x000A_- Confirm/adjust startup code:_x000A__x000A_      sbiScheduler := sbi.NewEventScheduler(clock) // real EventScheduler_x000A__x000A_      cdpServer := controller.NewCDPIServer(state, sbiScheduler /* or clock if needed */)_x000A__x000A_      ctlScheduler := controller.NewScheduler(state, sbiScheduler, cdpServer)_x000A__x000A_      agents := make([]*agent.Agent, 0)_x000A_      for _, node := range state.Nodes() {_x000A_          a := agent.NewAgent(agent.Config{_x000A_              NodeID:    node.ID,_x000A_              State:     state,_x000A_              Scheduler: sbiScheduler,_x000A_              // Telemetry client, CDPI client, etc._x000A_          })_x000A_          agents = append(agents, a)_x000A_      }_x000A__x000A_- Design note:_x000A_  - With a single scheduler:_x000A_    - All SBI events (controller + agents) share the same sim time base._x000A_    - `RunDue()` in the run-loop drives **all** SBI behavior._x000A__x000A_### 4. Add context-aware termination &amp; error handling_x000A__x000A_- Integrate `context.Context` into the run-loop:_x000A__x000A_      for {_x000A_          select {_x000A_          case &lt;-ctx.Done():_x000A_              return ctx.Err()_x000A_          default:_x000A_          }_x000A__x000A_          if clock.Now().After(endTime) {_x000A_              break_x000A_          }_x000A__x000A_          if err := timeCtrl.Step(); err != nil {_x000A_              return err_x000A_          }_x000A__x000A_          sbiSched.RunDue()_x000A_      }_x000A__x000A_- Decide on:_x000A_  - How end-of-scenario is detected:_x000A_    - Fixed `endTime`._x000A_    - Or a condition within `ScenarioState` (e.g. no more events, mission complete)._x000A_  - Graceful shutdown:_x000A_    - Agents may have `Stop()` methods._x000A_    - The runner should call them after the loop exits._x000A__x000A_### 5. Add a small integration test for the SBI run-loop_x000A__x000A_- Create a focused test, e.g. in `sim/runner` or `internal/sbi` test package:_x000A__x000A_  - Use:_x000A_    - A **fake** or fast `timectrl.Clock` that can be advanced programmatically._x000A_    - Real `EventScheduler` implementation._x000A_    - A minimal `ScenarioState` with:_x000A_      - A single node and interface._x000A_      - A link that becomes active at known times (if needed)._x000A_    - A very simple agent and/or controller scheduler logic:_x000A_      - E.g. schedule a no-op action at `T1`._x000A__x000A_- Test flow:_x000A__x000A_  1. Construct `ScenarioState`, `clock`, `sbiScheduler`._x000A_  2. Schedule a test event at `T1` via `EventScheduler.Schedule` that:_x000A_     - Increments a counter in the test._x000A_  3. Run a short `RunScenario` loop from `T0` to `T2`:_x000A_     - With `T0 &lt; T1 &lt; T2`._x000A_  4. Assert:_x000A_     - The scheduled callback has been executed exactly once._x000A_     - Sim time ends at/after `T2`._x000A_     - No panics or deadlocks._x000A__x000A_- Optional: add a second test that:_x000A_  - Schedules an agent action via SBI CDPI path (CreateEntryRequest)._x000A_  - Confirms that by `T &gt;= action.When`, the corresponding `ScenarioState` change has been applied._x000A__x000A_### 6. Documentation / comments_x000A__x000A_- Add high-level comments near the run-loop explaining:_x000A__x000A_  - Sim time vs wall time:_x000A_    - “All SBI scheduling is driven by simulation time via `EventScheduler`.”_x000A_  - The ordering:_x000A_    - Time step._x000A_    - Connectivity/orbital recompute (if separate)._x000A_    - SBI `RunDue()`._x000A__x000A_- This will make it easier to reason about behavior and to debug Scope 4 in the future._x000A__x000A_## Acceptance criteria_x000A__x000A_- **Run loop integration:**_x000A_  - There is a **single, clear run-loop** (or orchestrator function) that:_x000A_    - Advances sim time via the existing time controller._x000A_    - Calls `EventScheduler.RunDue()` on each iteration._x000A_  - The loop is context-aware and can terminate on:_x000A_    - `ctx.Done()`._x000A_    - End-of-scenario conditions._x000A__x000A_- **Unified scheduler:**_x000A_  - Controller `Scheduler` and all per-node `Agent`s share the **same** `EventScheduler` instance._x000A_  - All SBI events (`ScheduledAction`s, agent telemetry ticks, etc.) execute via this scheduler._x000A__x000A_- **EventScheduler API:**_x000A_  - `EventScheduler` has a `RunDue()` (or equivalent) method that:_x000A_    - Executes all events with `When &lt;= Now()` in a deterministic manner._x000A_  - Implementation is hooked up to the sim time controller, not wall-clock time._x000A__x000A_- **Behavioral correctness:**_x000A_  - When sim time passes a scheduled event’s `When`:_x000A_    - The event’s callback is executed exactly once._x000A_  - Agent actions scheduled through CDPI (beams/routes) are applied at the expected sim times._x000A_  - Telemetry ticks (if using the same scheduler) fire at the configured intervals._x000A__x000A_- **Tests:**_x000A_  - A small integration-style test exists that:_x000A_    - Drives the run-loop over a time range._x000A_    - Verifies at least one scheduled callback runs at/after its `When`._x000A_  - Tests pass with `go test ./...`._x000A__x000A_- **Repository health:**_x000A_  - `go build ./...` passes with the new run-loop wiring._x000A_  - `go test ./...` passes, including the new run-loop + EventScheduler integration test(s)._x000A_</S>
      <S N="State2">open</S>
    </MS>
  </Obj>
</Objs>